{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine BATCH II Scan Errors\r\n",
    "\r\n",
    "#### Updated: April 13, 2023 by Ashley Ferreira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction (to the issues we attempt to quantify)\r\n",
    "There are two potentail issues with the scanning we are trying to isolate and get an idea for how prevelant they are:\r\n",
    "1. Images are cropped too soon (causes aspect ratio to be less wide than expected)\r\n",
    "2. Images are out of phase (can see two sets of metadata on either side of ionogram instead of middle)\r\n",
    "\r\n",
    "Issue 1 is the easiest to detect by just reading in the pixel scale and calculating the aspect ratio, wheras for Issue 2 we need to use an optical character regonition program to estimate the number of characters in the metadata. Both of these cause us to not be able to see the ionogram trace correctly. Images like first and last ones of most subdirs are supposed to be off and not have the normal ionogram aspect ratios so it is normal to expect a certain small rate of these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup \r\n",
    "You will likely need to pip install tensorflow and keras_ocr as they do not come by default with anaconda, uncomment the cells below to do this if needed. Then run the cells to import the libraries adn set some of the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install keras_ocr --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\aferreira\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\aferreira\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "# imports\r\n",
    "import cv2\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import json\r\n",
    "\r\n",
    "import random\r\n",
    "from random import randrange\r\n",
    "from IPython.display import clear_output\r\n",
    "\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from matplotlib import rcParams as rc\r\n",
    "from matplotlib import rcParamsDefault\r\n",
    "from matplotlib.ticker import MaxNLocator\r\n",
    "import matplotlib.image as mpimg\r\n",
    "rc.update(rcParamsDefault)\r\n",
    "\r\n",
    "# replace this with your own library path for --user pip installs\r\n",
    "sys.path.append('C:/Users/aferreira/AppData/Roaming/Python/Python38/Scripts')\r\n",
    "import keras_ocr\r\n",
    "\r\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\r\n",
    "batchDir = 'L:/DATA/Alouette_I/BATCH_II_raw/'\r\n",
    "save_dir = 'U:/Downloads/' \r\n",
    "outFile = save_dir + 'chars_and_aspect_ratios_v2.csv'\r\n",
    "\r\n",
    "# set default saving settings\r\n",
    "append2outFile = True\r\n",
    "saveImages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inititalize Functions\r\n",
    "The main processing for this code uses two functions, read_all_rolls() which loops over all the batch 2 raw data ionogram images and saves the outputs from read_image() to a CSV file. This second function, read_image() reads in one image a time, whos path is passed it it by read_all_rolls(), and outputs the height and width along with the estimated character count of the metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, plotting=False):\r\n",
    "    '''\r\n",
    "    This function reads in one image a time and outputs the height \r\n",
    "    and width along with the estimated character count of the metadata.\r\n",
    "\r\n",
    "    Parameters:\r\n",
    "\r\n",
    "        image_path (str): path to the image\r\n",
    "\r\n",
    "        plotting (bool, optional): True for a verbose display mode to\r\n",
    "                                   illustrate the analysis in detail, \r\n",
    "                                   False otherwise\r\n",
    "\r\n",
    "    Returns:\r\n",
    "\r\n",
    "        char_count (int): estimated number of characters in the ionogram\r\n",
    "                          metadata (right now, only looks for numbers along\r\n",
    "                          bottom 20% of the image, usually only 15 expected)\r\n",
    "    \r\n",
    "        height (int): number of pixels along y-axis of original image\r\n",
    "        \r\n",
    "        width (int): number of pixels along x-axis of origional image\r\n",
    "\r\n",
    "        says_isis (bool): True if 'isis' independant of capitalization is \r\n",
    "                          present within the detected text, False otherwise\r\n",
    "    '''\r\n",
    "\r\n",
    "    # read in image using keras_ocr\r\n",
    "    image = keras_ocr.tools.read(image_path) \r\n",
    "\r\n",
    "    # extract height and width of image in pixels \r\n",
    "    height, width = image.shape[0], image.shape[1]\r\n",
    "\r\n",
    "    # cut image to just include bottom 20% of pixels\r\n",
    "    cropped_image = [image[height-height//5:height,:]]\r\n",
    "\r\n",
    "    # create predictions for location and value of characters\r\n",
    "    # on the cropped image, will output (word, box) tuples\r\n",
    "    prediction = pipeline.recognize(cropped_image)[0]\r\n",
    "\r\n",
    "    if plotting == True:\r\n",
    "        # display original image to make sure it is alright\r\n",
    "        plt.imshow(image)\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "        # display the cropped image\r\n",
    "        plt.imshow(cropped_image[0])\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "    # if no characters are found move on\r\n",
    "    if prediction == [[]]:\r\n",
    "        char_count = 0\r\n",
    "\r\n",
    "    # if characters are found look at the predictions\r\n",
    "    else:\r\n",
    "        if plotting == True:\r\n",
    "            # plot the predictied box and tuples\r\n",
    "            keras_ocr.tools.drawAnnotations(image=cropped_image[0], predictions=prediction)\r\n",
    "            plt.show()\r\n",
    "\r\n",
    "        # check how many are numbers since letters are often picked up from noise \r\n",
    "        # (sometimes something like a '0' maps to an 'o', but we only expect digits in metadata)\r\n",
    "\r\n",
    "        # loop over predicted (word, box) tuples and count number of digit characters\r\n",
    "        char_count = 0\r\n",
    "        says_isis = False\r\n",
    "        for p in prediction:\r\n",
    "\r\n",
    "            # select just the word part of the tuple\r\n",
    "            value = p[0]\r\n",
    "\r\n",
    "            if 'isis' in value.lower():\r\n",
    "                says_isis = True\r\n",
    "\r\n",
    "            # if word is composed of just integers then \r\n",
    "            # count how many and incriment char_count\r\n",
    "            if value.isdigit():\r\n",
    "                char_count += len(value)\r\n",
    "\r\n",
    "    return char_count, height, width, says_isis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_rolls(batchDir=batchDir, saveImages=saveImages):\r\n",
    "   '''\r\n",
    "   This function loops over all images nested within batchDir\r\n",
    "   and saves the outputs from read_image() to a CSV file.\r\n",
    "\r\n",
    "   Parameters:\r\n",
    "\r\n",
    "      batchDir (str, optional): path to directory of entire batch \r\n",
    "                                of ionogram scan images to analyze\r\n",
    "\r\n",
    "      saveImages (bool, optional): True to save all images with irregular\r\n",
    "                                    aspect ratios for visual inspection, \r\n",
    "                                    False otherwise\r\n",
    "\r\n",
    "   Returns:\r\n",
    "\r\n",
    "      None\r\n",
    "\r\n",
    "   '''\r\n",
<<<<<<< HEAD
    "   # check if there is already data in the file\r\n",
    "   if (os.path.exists(outFile) == False) or (os.path.exists(outFile) and os.stat(outFile).st_size == 0):\r\n",
    "      empty = True\r\n",
    "      last_file = ''\r\n",
    "   else:\r\n",
    "      empty = False\r\n",
    "      df = pd.read_csv(outFile)\r\n",
    "      last_image = batchDir + df['roll'].iloc[-1] + '/'+ df['subdir'].iloc[-1] + '/' + df['image'].iloc[-1]\r\n",
    "\r\n",
=======
>>>>>>> 057bc770dfcae1f01c29ab28da75647c525898d0
    "   # initialize lists to save values to in loop\r\n",
    "   rolls, subdirs, images = [], [], []\r\n",
    "   heights, widths, char_counts = [], [], []\r\n",
    "   says_isis_lst = []\r\n",
    "   \r\n",
    "   # loop over all rolls in the batch 2 raw data directory\r\n",
    "   raw_contents = os.listdir(batchDir)\r\n",
    "   for roll in raw_contents:\r\n",
    "\r\n",
    "      # loop over all subdirectories within the roll\r\n",
    "      roll_contents = os.listdir(batchDir + roll) \r\n",
    "      for subdir in roll_contents:\r\n",
    "\r\n",
    "         # loop over all images in the subdirectory\r\n",
    "         subdir_contents = os.listdir(batchDir + roll + '/' + subdir) \r\n",
    "         for image in subdir_contents:\r\n",
    "\r\n",
    "            # save full path of image\r\n",
    "            image_path = batchDir + roll + '/' + subdir + '/' + image\r\n",
    "\r\n",
<<<<<<< HEAD
    "            # if outFile is not empty just skip to that part of processing\r\n",
    "            if empty or image_path == last_image:\r\n",
    "               empty = True\r\n",
    "\r\n",
    "               # make sure path exits\r\n",
    "               pathExist = os.path.exists(image_path)\r\n",
    "               if pathExist:\r\n",
    "\r\n",
    "                  # save id of image\r\n",
    "                  rolls.append(roll)\r\n",
    "                  subdirs.append(subdir)\r\n",
    "                  images.append(image)\r\n",
    "\r\n",
    "                  # send to read_image to get aspect ratio and character count\r\n",
    "                  num_of_chars, h, w, says_isis = read_image(image_path)\r\n",
    "\r\n",
    "                  # aspect ratio could also be read in like\r\n",
    "                  #im = cv2.imread(image_path, 0)\r\n",
    "                  #h, w = im.shape\r\n",
    "\r\n",
    "                  # save values\r\n",
    "                  char_counts.append(num_of_chars)\r\n",
    "                  heights.append(h)\r\n",
    "                  widths.append(w)\r\n",
    "                  says_isis_lst.append(says_isis)\r\n",
    "                  \r\n",
    "                  # this is not used anymore but was helpful  \r\n",
    "                  # in exploring the acceptable aspect ratios\r\n",
    "                  if saveImages == True:\r\n",
    "                     if (w/h < 1.2) or (w/h > 3):\r\n",
    "                        save_name = save_dir + 'off_aspect_ratios/' + roll + '_' + subdir + '_' + image\r\n",
    "                        im = cv2.imread(image_path, 0)\r\n",
    "                        cv2.imwrite(save_name, im)   \r\n",
    "                        print('aspect ratio is off, saved image to:', save_name)               \r\n",
    "\r\n",
    "               # initialize dataframe and save results to csv\r\n",
    "               # (redoing this each interation to not loose information)\r\n",
    "               df_mapping_results = pd.DataFrame()\r\n",
    "\r\n",
    "               df_mapping_results['roll'] = rolls\r\n",
    "               df_mapping_results['subdir'] = subdirs\r\n",
    "               df_mapping_results['image'] = images\r\n",
    "               df_mapping_results['character_count'] = char_counts\r\n",
    "               df_mapping_results['height'] = heights\r\n",
    "               df_mapping_results['width'] = widths\r\n",
    "               df_mapping_results['says_isis'] = says_isis_lst\r\n",
    "\r\n",
    "               # mode = 'a' means it will append to existing data within the file\r\n",
    "               if append2outFile == True:\r\n",
    "                  mode = 'a' \r\n",
    "\r\n",
    "                  # wipe lists now that they have been saved\r\n",
    "                  rolls, subdirs, images = [], [], []\r\n",
    "                  heights, widths, char_counts = [], [], []\r\n",
    "                  says_isis_lst = []\r\n",
    "\r\n",
    "                  if os.path.exists(outFile):\r\n",
    "                        header = False \r\n",
    "                  else:\r\n",
    "                        header = True\r\n",
    "                  \r\n",
    "               else: \r\n",
    "                  # this overwrites existing file\r\n",
    "                  mode = 'w'\r\n",
    "                  header = True\r\n",
    "\r\n",
    "               df_mapping_results.to_csv(outFile, mode=mode, index=False, header=header)"
=======
    "            # make sure path exits\r\n",
    "            pathExist = os.path.exists(image_path)\r\n",
    "            if pathExist:\r\n",
    "\r\n",
    "               # save id of image\r\n",
    "               rolls.append(roll)\r\n",
    "               subdirs.append(subdir)\r\n",
    "               images.append(image)\r\n",
    "\r\n",
    "               # send to read_image to get aspect ratio and character count\r\n",
    "               num_of_chars, h, w, says_isis = read_image(image_path)\r\n",
    "\r\n",
    "               # aspect ratio could also be read in like\r\n",
    "               #im = cv2.imread(image_path, 0)\r\n",
    "               #h, w = im.shape\r\n",
    "\r\n",
    "               # save values\r\n",
    "               char_counts.append(num_of_chars)\r\n",
    "               heights.append(h)\r\n",
    "               widths.append(w)\r\n",
    "               says_isis_lst.append(says_isis)\r\n",
    "               \r\n",
    "               # this is not used anymore but was helpful  \r\n",
    "               # in exploring the acceptable aspect ratios\r\n",
    "               if saveImages == True:\r\n",
    "                  if (w/h < 1.2) or (w/h > 3):\r\n",
    "                     save_name = save_dir + 'off_aspect_ratios/' + roll + '_' + subdir + '_' + image\r\n",
    "                     im = cv2.imread(image_path, 0)\r\n",
    "                     cv2.imwrite(save_name, im)   \r\n",
    "                     print('aspect ratio is off, saved image to:', save_name)               \r\n",
    "\r\n",
    "            # initialize dataframe and save results to csv\r\n",
    "            # (redoing this each interation to not loose information)\r\n",
    "            df_mapping_results = pd.DataFrame()\r\n",
    "\r\n",
    "            df_mapping_results['roll'] = rolls\r\n",
    "            df_mapping_results['subdir'] = subdirs\r\n",
    "            df_mapping_results['image'] = images\r\n",
    "            df_mapping_results['character_count'] = char_counts\r\n",
    "            df_mapping_results['height'] = heights\r\n",
    "            df_mapping_results['width'] = widths\r\n",
    "            df_mapping_results['says_isis'] = says_isis_lst\r\n",
    "\r\n",
    "            # mode = 'a' means it will append to existing data within the file\r\n",
    "            if append2outFile == True:\r\n",
    "               mode = 'a' \r\n",
    "\r\n",
    "               # wipe lists now that they have been saved\r\n",
    "               rolls, subdirs, images = [], [], []\r\n",
    "               heights, widths, char_counts = [], [], []\r\n",
    "               says_isis_lst = []\r\n",
    "\r\n",
    "               if os.path.exists(outFile):\r\n",
    "                     header = False \r\n",
    "               else:\r\n",
    "                     header = True\r\n",
    "               \r\n",
    "            else: \r\n",
    "               # this overwrites existing file\r\n",
    "               mode = 'w'\r\n",
    "               header = True\r\n",
    "\r\n",
    "            df_mapping_results.to_csv(outFile, mode=mode, index=False, header=header)"
>>>>>>> 057bc770dfcae1f01c29ab28da75647c525898d0
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are images cropped to contain only bottom 20% of pixels?\r\n",
    "- The metadata we are interested in is expected to be at the bottom of the image, below the ionogram graph\r\n",
    "- Including the data from the ionogram graph makes the keras_ocr functions more likely to predict random words from the noise, so its best to lower the chances of this by cropping the image\r\n",
    "- Some images are upsidedown or for another reason will have their metadata cut off due to the crop but it is okay for us to underestimate, and this is preffered when compared to overestimating\r\n",
    "- There are some images which contain just long sections of metadata and these are not out of phase but would contribute to an overestimation and so cropping bottom 20% opposed to bottom 200 pixels allows us to filter out the characters on those images from view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible improvements to these functions:\r\n",
    "- loading the images in batches (tried but could only do two at a time with keras but may be worthwhile loading in whole subdirectory then just passing two to keras at a time)\r\n",
    "- writting to csv without using pandas/in a more clean way to constantly append (only append after 100 or something)\r\n",
    "- improve the ocr detection and regonition parts\r\n",
    "- make code more efficient, not focused too much with L drive and keras OCR being main limitting factors\r\n",
    "- use consistent mehtod of naming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the functions\r\n",
    "Below, I run the read_all_rolls() function for the batch 2 raw data directory and it saves the results as it processes. On my local computer, the processing time seems to be ~2s per image but it is highly dependant on the image, ranging from less than 1s to more than 7s, with most values lying in between that range."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 696ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 829ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 576ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 986ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "1/1 [==============================] - 1s 981ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 870ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 882ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 969ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 582ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 984ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 1s 583ms/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 880ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
>>>>>>> 057bc770dfcae1f01c29ab28da75647c525898d0
   "source": [
    "# run function for batch 2 results\r\n",
    "read_all_rolls() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DevSoftware': virtualenv)",
   "name": "python388jvsc74a57bd0ce9bdb650adbd0c373465918573be93876dd7fdc3f23b0f3367883e210ca8228"
  },
  "language_info": {
<<<<<<< HEAD
   "name": "python",
   "version": ""
=======
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
>>>>>>> 057bc770dfcae1f01c29ab28da75647c525898d0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}