{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ISIS Graph Reading\n",
    "The following code combines to create a notebook for finding fmin and maxdepth values from the ionogram trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import ntpath\n",
    "import scipy.signal as signal\n",
    "import traceback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdir path: L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B1-35-31 ISIS B D-1097\n"
     ]
    }
   ],
   "source": [
    "#Sub-directory path\n",
    "#SD_PATH = gen_ran_subdir(\"L:/DATA/ISIS/ISIS_101300030772/b*/B1*\")\n",
    "\n",
    "#Image path\n",
    "#I_PATH = gen_ran_img(SD_PATH, '/*')\n",
    "\n",
    "#For testing - only use same sub-directory (subdir)\n",
    "SD_PATH = \"L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B1-35-31 ISIS B D-1097\"\n",
    "#Folder containing 30 images for testing (very temporary)\n",
    "#I_PATH = gen_ran_img(SD_PATH, '/*')\n",
    "print (\"Subdir path:\", SD_PATH)\n",
    "#print (\"Random image in subdir path\", I_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VALUES\n",
    "\n",
    "#From scan2data > ionogram_grid_determination > grid_mapping.py\n",
    "#For ISIS-1\n",
    "HZ = [0.1,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,12.0,14.0,16.0,18.0,20.0]\n",
    "DEFAULT_HZ_COORD = [11,42,72,209,255,293,324,375,414,444,475,507,537,569,616,652,686,723,758,790,822,864]\n",
    "\n",
    "MEAN_HZ = [0.5*(num + DEFAULT_HZ_COORD[i+1])for i, num in enumerate(DEFAULT_HZ_COORD[:-1])]\n",
    "UPPER_LIMIT_HZ_COORD =[89] + MEAN_HZ \n",
    "LOWER_LIMIT_HZ_COORD = MEAN_HZ + [1510]\n",
    "\n",
    "KM_DEFAULT_100 = 55\n",
    "KM_DEFAULT_200 = 110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_loss(df, function_name, subdir_location, columns_to_extract=None, loss_extraction=None):\n",
    "    \"\"\"Generate a dataframe that records loss due to a self-imposed filter or a runtime programming error\n",
    "    \n",
    "    :param df: dataframe containing information of which image files did not pass a self-imposed filter or lead to runtime programming errors\n",
    "    :type df: class: `pandas.core.frame.DataFrame`\n",
    "    :param function_name: function or self-imposed filter leading to a loss\n",
    "    :type function_name: str\n",
    "    :param subdir_location: full path of the subdir\n",
    "    :type subdir_location: str\n",
    "    :param columns_to_extract: list of columns of df to extract, defaults to ['file_name']\n",
    "    :type columns_to_extract: list, optional\n",
    "    :param loss_extraction: whether a custom series is to be used to extract selected rows from the dataframe, defaults to []\n",
    "    :type loss_extraction: class: `pandas.core.series.Series`, optional\n",
    "    :returns: df_loss_extraction,loss_extraction i.e. dataframe containing file names leading to runtime errors or that do not pass pre-established filters (metadata size, ionogram size) as well as boolean series indicating which row of data to remove (==1)\n",
    "    :rtype: (class: `pandas.core.frame.DataFrame`,class: `pandas.core.series.Series`)\n",
    "    \"\"\"   \n",
    "    if columns_to_extract is None:\n",
    "        columns_to_extract = ['file_name']\n",
    "    if loss_extraction is None:\n",
    "        loss_extraction = []\n",
    "    if len(loss_extraction) == 0:\n",
    "        # function should return NA if there an error\n",
    "        loss_extraction = df.isna().any(axis=1)\n",
    "    # Record the files whose extraction was not successful\n",
    "    df_loss_extraction = df[loss_extraction].copy()\n",
    "    df_loss_extraction = df_loss_extraction[columns_to_extract]\n",
    "    df_loss_extraction['func_name'] = function_name\n",
    "    df_loss_extraction['subdir_name'] = subdir_location\n",
    "\n",
    "    return df_loss_extraction,loss_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All from scan2data > ionogram_grid_determination > grid_mapping\n",
    "def all_stack(df_img):\n",
    "    \"\"\"Returns the equally weighed sum of all the correctly extracted ionogram plot areas in a subsubdirectory \n",
    "    z\n",
    "    :param df_img: Dataframe contaning all the correctly extracted ionogram plot areas in a subsubdirectory (output of image_segmentation.segment_images_in_subdir.segment_images)\n",
    "    :type df_img: class: `pandas.core.frame.DataFrame`\n",
    "    :param cutoff_width: the width of an ionogram should be within cutoff_width of the median width of all the ionogram in a subdirectory (should be the same as the one used in scan2data.image_segmentation.segment_images_in_subdir.segment_images)\n",
    "    :type cutoff_width: int\n",
    "    :param cutoff_height: the height of an ionogram should be within cutoff_height of the median height of all the ionogram in a subdirectory (should be the same as the one used in scan2data.image_segmentation.segment_images_in_subdir.segment_images)\n",
    "    :type cutoff_height: int\n",
    "    :returns: weighed_sum i.e. equally weighed sum of all the extracted ionogram plot areas in a subsubdirectory\n",
    "    :rtype: class: `numpy.ndarray`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pad the image if needed\n",
    "    max_h = df_img[\"height\"].max()\n",
    "    max_w =  df_img[\"width\"].max()\n",
    "    median_h = int(np.median(df_img[\"height\"]))\n",
    "    median_w = int(np.median(df_img[\"width\"]))\n",
    "    \n",
    "\n",
    "    df_img[\"padded\"] = df_img[\"ionogram\"].apply(lambda img: np.pad( img, ((0,max_h- (np.shape(img))[0]),(0,max_w - np.shape(img)[1])),mode=\"constant\",constant_values=1))\n",
    "    \n",
    "    #Weighed sum of the ionograms in a subdirectory <-- Q: WHY DO WE HAVE TO TAKE THE WEIGHTED SUM OF ALL OF THE IONOGRAMS? SHOULDN'T EACH IONOGRAM BE ANALYZED INDIVIDUALLY?\n",
    "    #^^ resolved\n",
    "    weight = len(df_img.index)\n",
    "    weighed_sum = weight * np.sum((df_img[\"padded\"]).tolist(), axis = 0)\n",
    "    median_h = median_h if max_h>median_h else median_h-1\n",
    "\n",
    "    return weighed_sum[0:-(max_h-median_h),0:-(max_w-median_w)]\n",
    "\n",
    "\n",
    "def indices_highest_peaks(img, row_or_col,\n",
    "                      peak_prominence_threshold=0.1, distance_between_peaks=5):\n",
    "    \"\"\"Determines and returns the indices of peak median values from the rows or column of an image\n",
    "    \n",
    "    :param img: grayscale image in the form of an 2D uint8 array\n",
    "    :type img: class: `numpy.ndarray`\n",
    "    :param row_or_col: 0 for colum or 1 for row\n",
    "    :type row_or_col: int\n",
    "    :param peak_prominence_threshold: the threshold to detect peaks that correspond to the grid lines, defaults to 0.1\n",
    "    :type peak_prominence_threshold: int, optional\n",
    "    :param distance_between_peaks: the minimum number of samples between subsequent peaks, defaults to 5\n",
    "    :type distance_between_peaks: int, optional\n",
    "    :returns: select_peaks i.e. array of the indices of peak median values from the rows or column of an image\n",
    "    :rtype: class: `numpy.ndarray`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Median values along each row or column\n",
    "    median_values = np.median(img,row_or_col)\n",
    "\n",
    "    # Normalize median values so they are between 0 and 1\n",
    "    median_values_normalized = (median_values - np.min(median_values))/(np.max(median_values)-np.min(median_values))\n",
    "\n",
    "    # Prepare peaks for peak detection function: the peaks should be pointing upwards\n",
    "    peaks_function = 1 + -1*median_values_normalized \n",
    "\n",
    "    # Detect all peaks\n",
    "    select_peaks, _ = signal.find_peaks(peaks_function, distance=distance_between_peaks, prominence=peak_prominence_threshold) #from scipy.signal\n",
    "\n",
    "    #Remove edges from peaks\n",
    "    h,w = np.shape(img)\n",
    "    select_peaks = select_peaks[:w] if row_or_col == 0 else select_peaks[:h]\n",
    "    return select_peaks\n",
    "    \n",
    "\n",
    "def adjust_arr_peaks(weighed_sum,arr_peaks,desired_length,row_or_col,\n",
    "                  distance_between_peaks=30,peak_prominence_threshold=0.1,n_tries=1000,update_amount=0.01):\n",
    "    \"\"\"Adjust an array of peaks to the desired length and returns it. \n",
    "    \n",
    "     :param weighed_sum: equally weighed sum of all the image plot areas in a subsubdirectory \n",
    "     :type weighed_sum: class: `numpy.ndarray`\n",
    "     :param arr_peaks: array of peaks to adjust to the desired length\n",
    "     :type arr_peaks: class: `numpy.ndarray`\n",
    "     :param desired_length: number of elements desired in array\n",
    "     :type desired_length: int\n",
    "     :param row_or_col: 0 for colum or 1 for row\n",
    "     :type row_or_col: int\n",
    "     :param distance_between_peaks: the minimum number of samples between subsequent peaks, defaults to 30\n",
    "     :type distance_between_peaks: int, optional\n",
    "     :param peak_prominence_threshold: the threshold to detect peaks that correspond to the grid lines, defaults to 0.1\n",
    "     :type peak_prominence_threshold: int, optional\n",
    "     :param n_tries: the number of maximum tries to adjust arr, defaults to 1000\n",
    "     :type n_tries: int, optional\n",
    "     :param update_amount: by how much peak_prominence_threshold is updated for each iteration, defaults to 0.01\n",
    "     :type update_amount: int, optional\n",
    "     :returns: select_peaks i.e. adjusted array of the indices of peak median values from the rows or column of an image\n",
    "     :rtype: class: `numpy.ndarray`\n",
    "     ..note:: To prevent infinite loops, the script only runs for a maximum of n_tries times\n",
    "    \"\"\"\n",
    "    \n",
    "    arr_peaks = indices_highest_peaks(weighed_sum, row_or_col, peak_prominence_threshold, distance_between_peaks)  \n",
    "    #Q: WHY IS THE FUNCTION TAKING IN arr_peaks IF IT IS ALREADY CALCULATING IT HERE?\n",
    "    # ^^ resolved ?\n",
    "\n",
    "    # Adjust if lenght is not the desired length by re-running indices_highest_peaks with different parameters\n",
    "    while len(arr_peaks) != desired_length and n_tries !=0:\n",
    "        \n",
    "        if len(arr_peaks) > desired_length:\n",
    "            # increase peak_prominence_threshold \n",
    "            peak_prominence_threshold = peak_prominence_threshold + update_amount\n",
    "        else:\n",
    "            # decrease peak_prominence_threshold\n",
    "            peak_prominence_threshold = peak_prominence_threshold - update_amount\n",
    "        arr_peaks = indices_highest_peaks(weighed_sum, row_or_col,\n",
    "                                           peak_prominence_threshold, distance_between_peaks)\n",
    "        n_tries = n_tries - 1\n",
    "\n",
    "\n",
    "    return arr_peaks\n",
    "\n",
    "\n",
    "def get_grid_mappings(weighed_sum, use_defaults=True, min_index_row_peaks=40):\n",
    "    \"\"\"Determines and returns the the mapping between coordinate values and frequency/depth values in a subdirectory\n",
    "    \n",
    "    :param weighed_sum: equally weighed sum of all the image plot areas in a subsubdirectory \n",
    "    :type weighed_sum: class: `numpy.ndarray`\n",
    "    :param use_defaults: use default values , defaults to True\n",
    "    :type use_defaults: bool\n",
    "    :param min_index_row_peaks: starting index to consider for peaks to determine km lines,defaults to 40\n",
    "    :type min_index_row_peaks: int, optional\n",
    "    :returns:  col_peaks,row_peaks,mapping_Hz, mapping_km i.e. one-dimmensional array of detected peaks of ionogram by column, one-dimmensional array of detected  peaks of by row, dictionary mapping of depth (km) to y coordinates  , dictionary mapping of frequency (Hz) to x coordinates\n",
    "    :rtype: class: `numpy.ndarray`,class: `numpy.ndarray`,class: `dict`, class: `dict`\n",
    "    :raises Exception: returns np.nan,np.nan,np.nan,np.nan\n",
    "    \"\"\"\n",
    "    # Detect peaks\n",
    "    col_peaks = indices_highest_peaks(weighed_sum, 0)\n",
    "    row_peaks = indices_highest_peaks(weighed_sum, 1)\n",
    "\n",
    "    # Map col_peaks to Hz values\n",
    "    if len(col_peaks) == len(HZ):\n",
    "        mapping_Hz = dict(zip(HZ,col_peaks)) \n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            col_peaks = adjust_arr_peaks(weighed_sum, col_peaks, len(HZ), 0)\n",
    "            mapping_Hz = dict(zip(HZ,col_peaks)) \n",
    "\n",
    "            # Map adjusted HZ values to default coordinates if need be\n",
    "            if use_defaults:\n",
    "                for i,key in enumerate(HZ):\n",
    "                    if mapping_Hz[key] > UPPER_LIMIT_HZ_COORD[i] or mapping_Hz[key] < LOWER_LIMIT_HZ_COORD[i]:\n",
    "                        mapping_Hz[key] = DEFAULT_HZ_COORD[i]\n",
    "        except Exception:\n",
    "            if use_defaults:\n",
    "                 mapping_Hz = dict(zip(HZ,DEFAULT_HZ_COORD)) \n",
    "            else:    \n",
    "                return np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "\n",
    "    row_peaks = row_peaks[row_peaks > min_index_row_peaks]\n",
    "\n",
    "    try:\n",
    "        row_100 = row_peaks[0] #Should be around 30 for 100 km\n",
    "        row_200 = row_peaks[1] #Should be around 30 for 100 km\n",
    "    except Exception:\n",
    "        if not use_defaults:\n",
    "            return np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "        row_100 = KM_DEFAULT_100\n",
    "        row_200 = KM_DEFAULT_200\n",
    "    if use_defaults:\n",
    "        if abs(row_100 - KM_DEFAULT_100) > abs(KM_DEFAULT_200 - KM_DEFAULT_100):\n",
    "            row_100 = KM_DEFAULT_100\n",
    "        if abs(row_200 - KM_DEFAULT_200) > abs(KM_DEFAULT_200 - KM_DEFAULT_100):\n",
    "            row_200 = KM_DEFAULT_200   \n",
    "\n",
    "    mapping_km = {100:row_100,200:row_200}\n",
    "\n",
    "    return col_peaks, row_peaks, mapping_Hz, mapping_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From scan2data > ionogram_content_extraction > extract_all_coordinates_ionogram_trace.py\n",
    "def extract_ionogram_windows(binary_iono, stepSize=25, windowSize=(100, 100)):\n",
    "    \"\"\"Clean ionogram by using small thresholding windows\n",
    "\n",
    "    :param binary_iono: two-dimmensional uint8 array representing ionogram where the extracted threshold values are in while (1s) while the rest is in black (0s)\n",
    "    :type binary_iono: class: `numpy.ndarray`\n",
    "    :param stepSize: By how much window moves to the right and/or bottom\n",
    "    :type stepSize: int\n",
    "    :param windowSize: (height, width) of moving window\n",
    "    :type windowSize: tuple\n",
    "    :returns new_iono: cleaned ionogram represented by  two-dimmensional uint8 array\n",
    "    :rtype:  class: `numpy.ndarray`\n",
    "\n",
    "    \"\"\"\n",
    "    # TODOs: impove thresholding for windowing\n",
    "    threshold = np.mean(binary_iono) * 2\n",
    "\n",
    "    h_iono, w_iono = np.shape(binary_iono)\n",
    "    h_window, w_window = windowSize\n",
    "    new_iono = np.zeros((h_iono, w_iono))\n",
    "\n",
    "    for y in range(0, h_iono - h_window, stepSize):\n",
    "        for x in range(0, w_iono - w_window, stepSize):\n",
    "            box = binary_iono[y:y + h_window, x:x + w_window]\n",
    "            if np.mean(box) > threshold:\n",
    "                new_iono[y:y + h_window, x:x + w_window] = box\n",
    "\n",
    "    return new_iono\n",
    "\n",
    "def extract_fmin_and_max_depth(arr_adjusted_coord, min_depth=50, if_raw=False):\n",
    "    \"\"\"Extract the minimum detected frequency value and maximum detected depth\n",
    "    \n",
    "    :param arr_raw_coord:  one-dimmensional array of values of all the pixels corresponding to the ionogram trace\n",
    "    :type arr_raw_coord: class: `numpy.ndarray`\n",
    "    :param min_depth: minimum depth in km to be considered, defaults to 30\n",
    "    :type min_depth: int, optional\n",
    "    :param if_raw: if (x,y) rather than (Hz,km) coordinates are used, defaults to False\n",
    "    :type if_raw: bool, optional\n",
    "    :returns: fmin, depth_max i.e. minimum frequency detected and maximum depth detected\n",
    "    :rtype: float, float\n",
    "    :raises Exception: returns np.nan, np.nan\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        adjusted_x, adjusted_y = zip(*arr_adjusted_coord)\n",
    "        adjusted_x = np.array(adjusted_x)\n",
    "        adjusted_y = np.array(adjusted_y)\n",
    "\n",
    "        if if_raw:\n",
    "            min_depth= int(min_depth * KM_DEFAULT_100/100)\n",
    "\n",
    "        thresholded = adjusted_y > min_depth\n",
    "        adjusted_x_thresholded = adjusted_x[thresholded]\n",
    "        adjusted_y_thresholded = adjusted_y[thresholded]\n",
    "\n",
    "        fmin = min(adjusted_x_thresholded)\n",
    "        depth_max =  max(adjusted_y_thresholded)\n",
    "        return fmin, depth_max\n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "#From scan2data > ionogram_content_extraction > extract_all_coordinates_ionogram_trace.py   \n",
    "def extract_coord(iono, col_peaks, row_peaks,\n",
    "                  threshold=200, kernel_size_blurring=5):\n",
    "    \"\"\"Extract (x,y) of all the pixels corresponding to the ionogram trace\n",
    "\n",
    "    :param iono: two-dimmensional uint8 array representing raw ionogram\n",
    "    :type iono: class: `numpy.ndarray`\n",
    "    :param col_peaks: one-dimmensional array of detected peaks of ionogram by column\n",
    "    :type col_peaks: class: `numpy.ndarray`\n",
    "    :param row_peak: one-dimmensional array of detected  peaks of by row\n",
    "    :type row_peaks: class: `numpy.ndarray`\n",
    "    :param threshold: threshold of inverted pixel value to be considered ionogram data, defaults to 200\n",
    "    :type threshold: int, optional\n",
    "    :param kernel_size_blurring: kernel size for median filtering operation, defaults to 5\n",
    "    :type kernel_size_blurring: int, optional\n",
    "    :returns: arr_raw_coord0 ,arr_raw_coord: one-dimmensional array of (x,y) coordinates of all the pixels corresponding to the ionogram trace\n",
    "    :rtype: class: `numpy.ndarray`,class: `numpy.ndarray`\n",
    "    :raises Exception: returns np.nan,np.nan if there is an error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Shape of image\n",
    "    try:\n",
    "        h, w = np.shape(iono)\n",
    "\n",
    "        # Median blurring to remove salt and pepper noise\n",
    "        median_filtered_iono = cv2.medianBlur(iono, kernel_size_blurring)\n",
    "\n",
    "        # Invert image\n",
    "        inverted_iono = 255 - median_filtered_iono\n",
    "\n",
    "        # Correct image for grid ie remove the grid\n",
    "        grid = np.ones((h, w), np.uint8)\n",
    "        for i in col_peaks:\n",
    "            cv2.line(grid, (i, 0), (i, h), 0, 5, 1)\n",
    "        for i in row_peaks:\n",
    "            cv2.line(grid, (0, i), (w, i), 0, 5, 1)\n",
    "        corrected_iono = np.multiply(grid, inverted_iono)\n",
    "\n",
    "        # Assuming trace is going to be black ie mostly values close to 0 in the array\n",
    "        # Thus, the inverted trace is going to be white ie values most close to 252\n",
    "        # Threshold the image\n",
    "        _, thresholded_iono = cv2.threshold(corrected_iono, threshold, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Corrected ionogram by windowing operations\n",
    "        windowed = extract_ionogram_windows(thresholded_iono)\n",
    "\n",
    "        # y and x coordinates\n",
    "        arr_y, arr_x = np.where(thresholded_iono == 1)\n",
    "        arr_raw_coord0 = np.array(list(zip(arr_x, arr_y)), dtype=np.float64)\n",
    "\n",
    "        arr_y, arr_x = np.where(windowed == 1)\n",
    "        arr_raw_coord = np.array(list(zip(arr_x, arr_y)), dtype=np.float64)\n",
    "\n",
    "        return arr_raw_coord0, arr_raw_coord  # raw_coord, windowed_coord    `\n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "#From scan2data > ionogram_content_extraction > extract_all_coordinates_ionogram_trace.py\n",
    "def map_coordinates_positions_to_values(arr_raw_coord, col_peaks, row_peaks, mapping_Hz, mapping_km):\n",
    "    \"\"\"Map (x,y) position coordinates of ionogram pixels to (Hz,km) values\n",
    "\n",
    "    :param arr_raw_coord:  one-dimmensional array of (x,y) coordinates of all the pixels corresponding to the ionogram trace\n",
    "    :type arr_raw_coord: class: `numpy.ndarray\n",
    "    :param col_peaks: one-dimmensional array of detected peaks of ionogram by column\n",
    "    :type col_peaks: class: `numpy.ndarray`\n",
    "    :param row_peak: one-dimmensional array of detected  peaks of by row\n",
    "    :type row_peaks: class: `numpy.ndarray`\n",
    "    :param mapping_Hz: dictionary mapping of frequency (Hz) to x coordinates\n",
    "    :type mapping_Hz: class: `dict`\n",
    "    :param mapping_km:  dictionary mapping of depth (km) to y coordinates\n",
    "    :type mapping_km: class: `dict`\n",
    "    :returns: arr_adjusted_coord: one-dimmensional array of (Hz,km) values of all the pixels corresponding to the ionogram trace\n",
    "    :rtype: class: `numpy.ndarray`\n",
    "    \"\"\"\n",
    "\n",
    "    # check if there are any coordinate values recorded for the ionogram\n",
    "    if len(arr_raw_coord)==0:\n",
    "        return arr_raw_coord\n",
    "\n",
    "    # remove outliers ie coordinates less coordinates corresponding to 0.5 Hz or more than corresponding to 11.5 Hz\n",
    "    col_peaks = np.array(list(mapping_Hz.values()))  # use the modified col_peaks ie the one with exactly 13 values\n",
    "\n",
    "    mask = np.logical_or(arr_raw_coord[:, 0] < col_peaks.min(), arr_raw_coord[:, 0] > col_peaks.max())\n",
    "    arr_raw_coord = arr_raw_coord[~mask, :]\n",
    "\n",
    "    # map (y,x) to (km, Hz)\n",
    "    km_values, index_values_km = list(zip(*list(mapping_km.items())))\n",
    "    multiplier = (km_values[1] - km_values[0]) / (index_values_km[1] - index_values_km[0])\n",
    "\n",
    "    arr_adjusted_coord = arr_raw_coord.copy()\n",
    "    arr_adjusted_coord[:, 1] = km_values[0] + (arr_adjusted_coord[:, 1] - index_values_km[0]) * multiplier\n",
    "\n",
    "    # reverse mapping_km mappings\n",
    "    mapping_Hz_reversed = {mapping_Hz[freq_key]: freq_key for freq_key in mapping_Hz}\n",
    "    arr_adjusted_x = np.array([])\n",
    "    for coord_x in arr_adjusted_coord[:, 0]:\n",
    "        if coord_x in col_peaks:\n",
    "            new_coord_x = mapping_Hz_reversed[coord_x]\n",
    "        else:\n",
    "            # find the 2 closest values and linearly interpolate from there\n",
    "            leftmost_val = col_peaks[col_peaks < coord_x].max()\n",
    "            rightmost_val = col_peaks[col_peaks > coord_x].min()\n",
    "            multiplier = (mapping_Hz_reversed[rightmost_val] - mapping_Hz_reversed[leftmost_val]) / (\n",
    "                        rightmost_val - leftmost_val)\n",
    "            new_coord_x = mapping_Hz_reversed[leftmost_val] + multiplier * (coord_x - leftmost_val)\n",
    "\n",
    "        arr_adjusted_x = np.append(arr_adjusted_x, new_coord_x)\n",
    "    arr_adjusted_coord[:, 0] = arr_adjusted_x\n",
    "\n",
    "    return arr_adjusted_coord\n",
    "\n",
    "#From scan2data > ionogram_content_extraction > extract_all_coordinates_ionogram_trace.py\n",
    "def extract_coord_subdir_and_param(df_img, subdir_location, col_peaks, row_peaks, mapping_Hz, mapping_km):\n",
    "    \"\"\"Extract the raw, windowed coordinates in all the raw extracted ionograms from a subdirectory, map those coordinates into (Hz, km) and extract select parameterd\n",
    "\n",
    "    :param df_img: Dataframe containing all the correctly extracted ionogram plot areas in a subsubdirectory (output of image_segmentation.segment_images_in_subdir.segment_images)\n",
    "    :type df_img: class: `pandas.core.frame.DataFrame`\n",
    "    :param subdir_location: Path of the subdir_location\n",
    "    :type subdir_location: string\n",
    "    :param col_peaks: one-dimmensional array of detected peaks of ionogram by column\n",
    "    :type col_peaks: class: `numpy.ndarray`\n",
    "    :param row_peak: one-dimmensional array of detected  peaks of by row\n",
    "    :type row_peaks: class: `numpy.ndarray`\n",
    "    :param mapping_Hz: dictionary mapping of frequency (Hz) to x coordinates\n",
    "    :type mapping_Hz: class: `dict`\n",
    "    :param mapping_km:  dictionary mapping of depth (km) to y coordinates\n",
    "    :type mapping_km: class: `dict`\n",
    "    :returns: df_img, df_loss: i.e.  i.e. dataframe containing extracted ionogram trace coordinates from all the extracted raw ionograms in a directory,dataframe containing file names leading to runtime errors\n",
    "    :rtype: class: `pandas.core.frame.DataFrame`, class: `pandas.core.frame.DataFrame`\n",
    "\n",
    "    \"\"\"\n",
    "    # Get (x,y) coordinates of trace\n",
    "    if(len(df_img)==1):\n",
    "        c1, c2 = zip(*df_img['ionogram'].map(lambda iono: extract_coord(iono, col_peaks, row_peaks)))\n",
    "        df_img['raw_coord'] = list(c1)\n",
    "        df_img['window_coord'] = list(c2)\n",
    "        \n",
    "    else :\n",
    "        df_img['raw_coord'], df_img['window_coord'] = zip(\n",
    "            *df_img['ionogram'].map(lambda iono: extract_coord(iono, col_peaks, row_peaks)))\n",
    "\n",
    "    # Remove loss\n",
    "    df_loss_coord, loss_coord = record_loss(df_img,\n",
    "                                            'ionogram_content_extraction.extract_all_coordinates_ionogram_trace.extract_coord_subdir',\n",
    "                                            subdir_location) #from helper functions.py\n",
    "    df_img = df_img[~loss_coord]\n",
    "\n",
    "    #df_img.to_csv(\"U:/alouette-scanned-ionograms-processing/df_img.csv\", index=False)\n",
    "\n",
    "    # (Hz, km) coordinates\n",
    "    df_img['mapped_coord'] = df_img['window_coord'].map(\n",
    "        lambda windowed: map_coordinates_positions_to_values(windowed, col_peaks, row_peaks, mapping_Hz, mapping_km))\n",
    "    \n",
    "\n",
    "    # Select parameters extracted\n",
    "    #df_mapped_temp = df_img['mapped_coord'].map(lambda mapped_coord: extract_fmin_and_max_depth(mapped_coord))) #from extract_select_parameters.py  #Q: I wonder if f_min and depth_max is actually scientifically useful? Why don't we extract mapped_coord instead?\n",
    "    df_mapped_temp = df_img.apply(lambda row: extract_fmin_and_max_depth(row['mapped_coord']), axis = 1, result_type = \"expand\")\n",
    "    df_img = df_img.assign(fmin = df_mapped_temp[0])\n",
    "    df_img = df_img.assign(max_depth = df_mapped_temp[1])\n",
    "\n",
    "    # Remove loss.\n",
    "    df_loss_param, loss_param = record_loss(df_img,\n",
    "                                            'ionogram_content_extraction.extract_select_parameters.extract_fmin_and_max_depth',\n",
    "                                            subdir_location)\n",
    "    df_img = df_img[~loss_param]\n",
    "\n",
    "    df_loss = pd.concat([df_loss_coord, df_loss_param])\n",
    "\n",
    "    return df_img, df_loss\n",
    "\n",
    "#From scan2data > image_segmentation > extract_ionogram_from_scan.py\n",
    "def limits_ionogram(raw_img, row_or_col, starting_index_col=15):\n",
    "    \"\"\"Returns the upper and lower limits of the ionogram part of the scan by row or column using mean-based thresholding\n",
    "    \n",
    "    :param starting_img: UTF-8 grayscale 2D array of values ranging from [0,255] representing raw scanned image\n",
    "    :type starting_img: class: `numpy.ndarray`\n",
    "    :param row_or_col: 0 for column or 1 for row\n",
    "    :type row_or_col: int\n",
    "    :param starting_index_col: where the ionogram starting column should be after to protect against cuts, defaults to 15\n",
    "    :type starting_index_col: int, optional\n",
    "    :return:  limits[0],limits[-1] i.e. the upper and lower limits of the ionogram part of the scan by row (row_or_col=1) or column (row_or_col=0)\n",
    "    :rtype: int,int\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Mean pixel values by by row/col\n",
    "    mean_values = np.mean(raw_img, row_or_col)\n",
    "    \n",
    "    # Normalized mean values\n",
    "    normalized_mean_values = (mean_values - np.min(mean_values))/np.max(mean_values)\n",
    "    \n",
    "    # Threshold is the overall mean value of the entire image\n",
    "    threshold = np.mean(normalized_mean_values)\n",
    "    \n",
    "    if row_or_col == 0:\n",
    "        #Protect against scans that includes cuts from another ionogram ex:R014207956\\2394-1B\\51.png \n",
    "        limits = [i for i, mean in enumerate(normalized_mean_values) if mean >threshold and i > starting_index_col]\n",
    "    else:\n",
    "        limits = [i for i, mean in enumerate(normalized_mean_values) if mean >threshold]\n",
    "        \n",
    "    return limits[0],limits[-1]\n",
    "\n",
    "#From scan2data > image_segmentation > extract_ionogram_from_scan.py\n",
    "def extract_ionogram(raw_img_array):\n",
    "    \"\"\"Extract ionogram part of a raw scanned image and return coordinates delimiting its limits\n",
    "    \n",
    "    :param raw_img_array: UTF-8 grayscale 2D array of values ranging from [0,255] representing raw scanned image\n",
    "    :type raw_img_array: class: `numpy.ndarray`\n",
    "    :return: (limits, ionogram) i.e. (list of coordinates delimiting the limits of the ionogram part of a raw scanned image formatted as [x_axis_left_limit ,x_axis_right_limit, y_axis_upper_limit, y_axis_lower_limit], UTF-8 grayscale 2D array of values ranging from [0,255] representing ionogram part of scanned image)\n",
    "    :rtype: (list,numpy.ndarray)\n",
    "    :raises Exception: returns [],np.nan if there is an error\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract coordinate delimiting the ionogram part of the scan\n",
    "        x_axis_left_limit ,x_axis_right_limit = limits_ionogram(raw_img_array, 0)\n",
    "        y_axis_upper_limit, y_axis_lower_limit = limits_ionogram(raw_img_array, 1)\n",
    "\n",
    "        # Extract ionogram part\n",
    "        ionogram = raw_img_array[y_axis_upper_limit:y_axis_lower_limit,x_axis_left_limit:x_axis_right_limit]\n",
    "\n",
    "        #Just added for checking the metadata part of image\n",
    "        imgMetadataPart = raw_img_array[y_axis_upper_limit:y_axis_lower_limit, 15:x_axis_left_limit - 1]\n",
    "        # cv2.imshow(\"test Metadata\", imgMetadataPart)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        limits = [x_axis_left_limit ,x_axis_right_limit, y_axis_upper_limit, y_axis_lower_limit]\n",
    "        return (limits, ionogram)\n",
    "\n",
    "    except Exception:\n",
    "        return ([],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESSING\n",
    "# scan2data > image_segmentation > segment_images_in_subdir\n",
    "def segment_images(subdir_location, regex_img,\n",
    "                  cutoff_width = 300, cutoff_height=150,\n",
    "                  min_leftside_meta_width = 50, min_bottomside_meta_height=15): #min_bottomside_meta_height=25\n",
    "    \"\"\"From all the raw images in a subsubdirectory, extract the ionogram and trimmed metadata while handling errors and recording loss of data\n",
    "    \n",
    "    :param subdir_location: full path of the subdir\n",
    "    :type subdir_location: str\n",
    "    :param regex_img: regular expression to extract image\n",
    "    :type regex_img: str\n",
    "    :param cutoff_width: the width of an ionogram should be within cutoff_width of the median width of all the ionogram in a subdirectory, defaults to 300\n",
    "    :type cutoff_width: int, optional\n",
    "    :param cutoff_height: the height of an ionogram should be within cutoff_height of the median height of all the ionogram in a subdirectory, defaults to 150\n",
    "    :type cutoff_height: int, optional\n",
    "    :param min_leftside_meta_width: the minimum width of trimmed metadata located on the left side of ionograms, defaults to 50\n",
    "    :type min_leftside_meta_width: int, optional\n",
    "    :param min_bottomside_meta_height: the minimum height of trimmed metadata located on the bottom side of ionograms, defaults to 25\n",
    "    :type min_bottomside_meta_height: int, optional\n",
    "    :return: df_img,df_loss,df_outlier i.e. dataframe containing extracted ionograms and trimmed metadata from all the images in a directory,dataframe containing file names leading to runtime errors, dataframe containing file names that do not pass pre-established filters (metadata size, ionogram size)\n",
    "    :rtype: (class: `pandas.core.frame.DataFrame`,class: `pandas.core.frame.DataFrame`,class: `pandas.core.frame.DataFrame`)\n",
    "    .. todo:: complete flip_vertical ie list of subdirectories requiring flipping\n",
    "    \"\"\"\n",
    "    # List of raw image files in subdirectory\n",
    "    regex_raw_image = subdir_location + regex_img\n",
    "    list_images = glob.glob(regex_raw_image)\n",
    "\n",
    "    ## If flipping/rotating is required for all the images in the subdirectory\n",
    "    #path = subdir_location.replace('\\\\', '/')\n",
    "    #flip_vertical = any(subdir_dir in path for subdir_dir in LIST_FLIP_VERTICAL)\n",
    "    #rotate_180 = any(subdir_dir in path for subdir_dir in LIST_ROTATE_180)\n",
    "\n",
    "    # DataFrame for processing\n",
    "    df_img = pd.DataFrame(data = {'file_name': list_images})     \n",
    "\n",
    "    #Read each image in an 2D UTF-8 grayscale array\n",
    "    #if flip_vertical:\n",
    "        #df_img['raw'] = df_img['file_name'].map(lambda file_name: cv2.flip(cv2.imread(file_name,0),1))\n",
    "    #else:\n",
    "    df_img['raw'] = df_img['file_name'].map(lambda file_name: cv2.imread(file_name,0))\n",
    "    \n",
    "    # Extract ionogram and coordinates delimiting its limits\n",
    "    #extract_ionogram is being imported \n",
    "    df_img['limits'], df_img['ionogram'] = zip(*df_img['raw'].map(lambda raw_img: extract_ionogram(raw_img))) #from extract_ionogram_from_scan.py\n",
    "\n",
    "    # Record the files whose ionogram extraction was not successful\n",
    "    df_loss_ion_extraction, loss_ion_extraction = record_loss(df_img,'image_segmentation.extract_ionogram_from_scan.extract_ionogram',subdir_location)\n",
    "\n",
    "    # Remove files whose ionogram extraction was not successful\n",
    "    df_img = df_img[~loss_ion_extraction]\n",
    "\n",
    "    #if rotate_180:\n",
    "        #df_img['ionogram'] = df_img['ionogram'].map(lambda ionogram: np.rot90(ionogram, 2))\n",
    "\n",
    "    # Extract the shape of each ionogram in subdirectory\n",
    "    df_img['height'],df_img['width'] = zip(*df_img['ionogram'].map(lambda array_pixels: array_pixels.shape))\n",
    "\n",
    "    #Find median height and width of ionogram in subdirectory\n",
    "    median_height = np.median(df_img['height'])\n",
    "    median_width = np.median(df_img['width'])\n",
    "\n",
    "    # Find and remove ionogram outliers    \n",
    "    conditional_list_ionogram = [abs(df_img['height'] -median_height) > cutoff_height,abs(df_img['width'] - median_width) > cutoff_width]\n",
    "    outlier_ionogram = np.any(conditional_list_ionogram,axis = 0)\n",
    "\n",
    "    df_outlier_ionogram,_ = record_loss(df_img,'image_segmentation.segment_images_in_subdir.segment_images: iono size outlier',subdir_location,['file_name','height','width'],outlier_ionogram)\n",
    "\n",
    "    # Log outlier\n",
    "    if not df_outlier_ionogram.empty:\n",
    "        df_outlier_ionogram[ 'details'] = df_outlier_ionogram.apply(lambda row: 'height: ' + str(row['height'])+',width: ' + str(row['width']), 1)\n",
    "        df_outlier_ionogram = df_outlier_ionogram[['file_name','func_name','subdir_name','details']]\n",
    "    else:\n",
    "        df_outlier_ionogram = df_outlier_ionogram[['file_name','func_name','subdir_name']]\n",
    "\n",
    "    # Remove outlier\n",
    "    df_img = df_img[~outlier_ionogram]\n",
    "\n",
    "\n",
    "    # Raw metadata\n",
    "    #df_img['metadata_type'], df_img['raw_metadata'] = zip(*df_img.apply(lambda row: extract_metadata(row['raw'], row['limits']), 1)) #from extract_metadata_from_scan\n",
    "    #if rotate_180:\n",
    "        #df_img['raw_metadata'] = df_img['raw_metadata'].map(lambda raw_metadata: np.rot90(raw_metadata, 2))\n",
    "\n",
    "    # There should be no metadata on left and top, especially after flipping\n",
    "    '''outlier_metadata_location = np.any([df_img['metadata_type'] == 'right', df_img['metadata_type']=='top'], axis=0)\n",
    "    df_outlier_metadata_location ,_ =  record_loss(df_img,'image_segmentation.segment_images_in_subdir.segment_images: metadata not on left or bottom',subdir_location,\n",
    "                                         ['file_name','metadata_type'],outlier_metadata_location )\n",
    "\n",
    "    if not df_outlier_metadata_location.empty:\n",
    "        df_outlier_metadata_location['details'] = df_outlier_metadata_location.apply(lambda row: str(row['metadata_type']),1)\n",
    "        df_outlier_metadata_location = df_outlier_metadata_location[['file_name','func_name','subdir_name','details']]\n",
    "    else:\n",
    "        df_outlier_metadata_location = df_outlier_metadata_location[['file_name','func_name','subdir_name']]\n",
    "    \n",
    "    # Remove loss from detected metadata not being on the left or bottom\n",
    "    df_img = df_img[~outlier_metadata_location]'''\n",
    "\n",
    "    # Trimmed metadata\n",
    "    #df_img['trimmed_metadata'] = df_img.apply(lambda row: trimming_metadata(row['raw_metadata'], row['metadata_type']), 1) #from trim_raw_metadata.py\n",
    "    #df_loss_trim,loss_trim = record_loss(df_img,'image_segmentation.trim_raw_metadata.trimming_metadata',subdir_location)\n",
    "\n",
    "\n",
    "    # Remove files whose metadata trimming was not successful\n",
    "    #df_img = df_img[~loss_trim]\n",
    "\n",
    "\n",
    "    # Check if metadata too small\n",
    "    #df_img['meta_height'],df_img['meta_width'] = zip(*df_img['trimmed_metadata'].map(lambda array_pixels: array_pixels.shape))\n",
    "    #outlier_size_metadata = np.logical_or(np.logical_and(df_img['metadata_type'] == 'left', \n",
    "                                                      #df_img['meta_width'] < min_leftside_meta_width),\n",
    "                                       #np.logical_and(df_img['metadata_type'] == 'bottom', \n",
    "                                                     # df_img['meta_height'] < min_bottomside_meta_height))\n",
    "\n",
    "    #df_outlier_metadata_size, _ = record_loss(df_img,'image_segmentation.segment_images_in_subdir.segment_images: metadata size outlier',subdir_location,\n",
    "                                          # ['file_name','metadata_type','meta_height','meta_width'],outlier_size_metadata)\n",
    "\n",
    "    #if not df_outlier_metadata_size.empty:\n",
    "        #df_outlier_metadata_size['details'] = df_outlier_metadata_size.apply(lambda row: row['metadata_type'] + '_height: ' + \\\n",
    "                                                    #str(row['meta_height'])+',width: ' + str(row['meta_width']),1)\n",
    "        #df_outlier_metadata_size = df_outlier_metadata_size[['file_name','func_name','subdir_name','details']]\n",
    "\n",
    "    #else:\n",
    "        #df_outlier_metadata_size = df_outlier_metadata_size[['file_name','func_name','subdir_name']]\n",
    "\n",
    "    # Remove files whose metadata too small\n",
    "    #df_img = df_img[~outlier_size_metadata]\n",
    "\n",
    "\n",
    "    # Dataframe recording loss from programming errors\n",
    "    df_loss = pd.concat([df_loss_ion_extraction])\n",
    "\n",
    "    # Dataframe recording loss from various filters i.e. metadata too small, ionogram too small/big\n",
    "    df_outlier = pd.concat([df_outlier_ionogram]) #df_outlier_metadata_location\n",
    "\n",
    "    return df_img, df_loss, df_outlier\n",
    "\n",
    "#From scan2data > process_directory\n",
    "def process_subdirectory(subdir_path, regex_images):\n",
    "    \"\"\"Transform raw scanned images in a subdirectory into information\n",
    "\n",
    "    :param subdir_path: path of subdir_path\n",
    "    :type subdir_path: str\n",
    "    :param regex_img: regular expression to extract images ex: '*.png'\n",
    "    :type regex_img: str\n",
    "    :param output_folder_if_pickle: output folder for pickle, use None if no pickle\n",
    "    :type output_folder_if_pickle: string\n",
    "    :param min_n_leftside_metadata: minimum number of ionograms with metadata on the left to be able to call metadata_translation.leftside_metadata_grid_mapping, defaults to 10\n",
    "    :type min_n_leftside_metadata: int, optional\n",
    "    :returns: df_processed, df_loss, df_outlier: :  dataframe containing data from running the full processing pipeline,dataframe containing file names leading to runtime errors, dataframe containing file names that do not pass pre-established filters (metadata size, ionogram size)\n",
    "    :rtype: class: `pandas.core.frame.DataFrame`,class: `pandas.core.frame.DataFrame`,class: `pandas.core.frame.DataFrame`\n",
    "    \"\"\"\n",
    "    # Run segment_images on the subdirectory\n",
    "    df_img, df_loss, df_outlier = segment_images(subdir_path, regex_images) #from image_segmentation.segment_images_in_subdir.py\n",
    "\n",
    "    # Determine ionogram grid mappings used to map (x,y) pixel coordinates of ionogram trace to (Hz, km) values\n",
    "    stack = all_stack(df_img) #from grid_mapping.py\n",
    "    # Roksana comment: the logic should be reviewed\n",
    "    # if stack would be empty the below function faced with error. It happens when the directory has only one file.\n",
    "    #^^ above comments have most likely been resolved \n",
    "\n",
    "    col_peaks, row_peaks, mapping_Hz, mapping_km = get_grid_mappings(stack) #from grid_mapping\n",
    "\n",
    "    # Split left from bottom-side metadata\n",
    "    #df_img_left = df_img.loc[df_img['metadata_type'] == 'left']\n",
    "    #df_img_bottom = df_img.loc[df_img['metadata_type'] == 'bottom']\n",
    "    \n",
    "    #if len(df_img_left) > 9:\n",
    "        #Get metadata\n",
    "        #df_img_left, df_loss_meta_left, dict_mapping_left, dict_hist_left = get_leftside_metadata(df_img_left, subdir_path) #from metadata_translation.translate_leftside_metadata\n",
    "        #df_loss = df_loss.append(df_loss_meta_left)\n",
    "        #Extract the coordinates of the ionogram trace (black), Map the (x,y) pixel coordinates to (Hz, km) values\n",
    "        #extract_coord_subdir_and_param is imported function\n",
    "        #df_processed_left, df_loss_coord_left = extract_coord_subdir_and_param(df_img_left, subdir_path, col_peaks, row_peaks, mapping_Hz, mapping_km) #from ionogram_content_extraction.extract_all_coordinates_ionogram_trace\n",
    "    #else:\n",
    "        #df_loss = df_loss.append(df_img_left)\n",
    "        #df_processed_left = pd.DataFrame()\n",
    "        #df_loss_coord_left = pd.DataFrame()\n",
    "    \n",
    "    #if len(df_img_bottom) > 9:\n",
    "        #df_img_bottom, df_loss_meta_bottom, dict_mapping_bottom, dict_hist_bottom = get_bottomside_metadata(df_img_bottom, subdir_path) #from metadata_translation.translate_bottomside_metadata\n",
    "        #df_loss = df_loss.append(df_loss_meta_bottom)\n",
    "        #if len(df_img_bottom) > 0:\n",
    "            #Extract the coordinates of the ionogram trace (black), Map the (x,y) pixel coordinates to (Hz, km) values\n",
    "            \n",
    "    df_processed_bottom, df_loss_coord_bottom = extract_coord_subdir_and_param(df_img, subdir_path, col_peaks, row_peaks, mapping_Hz, mapping_km) #from ionogram_content_extraction.extract_all_coordinates_ionogram_trace\n",
    "        #else :\n",
    "            #df_processed_bottom = pd.DataFrame()\n",
    "            #df_loss_coord_bottom = pd.DataFrame()\n",
    "            \n",
    "    #else:\n",
    "        #df_loss = df_loss.append(df_img_bottom)\n",
    "        #df_processed_bottom = pd.DataFrame()\n",
    "        #df_loss_coord_bottom = pd.DataFrame()\n",
    "\n",
    "    #Recombine left and bottom-side metadata images\n",
    "    df_processed = pd.concat([df_processed_bottom])\n",
    "    df_loss_coord = pd.concat([df_loss_coord_bottom])\n",
    "    \n",
    "    df_processed['mapping_Hz'] = [mapping_Hz] * len(df_processed.index)\n",
    "    df_processed['mapping_km'] = [mapping_km] * len(df_processed.index)\n",
    "\n",
    "    df_loss = pd.concat([df_loss, df_loss_coord])\n",
    "    df_processed.to_csv(\"C:/Users/spunchiwickrama/Documents/Projects/ISIS_I/iono-processed-subdirtest.csv\")\n",
    "    return df_processed, df_loss, df_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(                                             file_name  \\\n",
      "2    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "3    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "4    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "5    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "6    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "..                                                 ...   \n",
      "223  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "224  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "225  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "226  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "227  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "\n",
      "                                                   raw                limits  \\\n",
      "2    [[35, 25, 10, 4, 1, 1, 7, 10, 10, 12, 18, 16, ...  [206, 1326, 28, 358]   \n",
      "3    [[8, 2, 114, 30, 10, 7, 15, 1, 8, 4, 5, 3, 7, ...  [200, 1318, 28, 358]   \n",
      "4    [[21, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0...  [193, 1311, 28, 358]   \n",
      "5    [[9, 23, 15, 10, 2, 3, 7, 8, 9, 51, 84, 1, 1, ...  [188, 1326, 28, 359]   \n",
      "6    [[23, 4, 14, 12, 8, 5, 8, 9, 7, 1, 2, 5, 6, 9,...   [18, 1298, 28, 354]   \n",
      "..                                                 ...                   ...   \n",
      "223  [[29, 0, 0, 11, 1, 2, 3, 1, 1, 2, 1, 2, 1, 0, ...   [16, 1318, 23, 354]   \n",
      "224  [[13, 4, 4, 10, 4, 2, 1, 8, 4, 2, 1, 3, 1, 5, ...   [16, 1319, 23, 355]   \n",
      "225  [[20, 81, 62, 4, 3, 6, 3, 2, 6, 12, 2, 6, 2, 7...   [16, 1332, 23, 353]   \n",
      "226  [[12, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 1, 6...   [16, 1327, 23, 355]   \n",
      "227  [[49, 18, 70, 5, 1, 1, 0, 1, 2, 0, 2, 1, 1, 0,...   [16, 1308, 23, 352]   \n",
      "\n",
      "                                              ionogram  height  width  \\\n",
      "2    [[169, 153, 110, 125, 166, 171, 121, 130, 161,...     330   1120   \n",
      "3    [[137, 107, 173, 161, 128, 109, 167, 170, 147,...     330   1118   \n",
      "4    [[116, 135, 159, 175, 107, 118, 166, 169, 123,...     330   1118   \n",
      "5    [[139, 111, 153, 170, 144, 111, 140, 171, 158,...     331   1138   \n",
      "6    [[164, 142, 111, 164, 174, 154, 106, 141, 178,...     326   1280   \n",
      "..                                                 ...     ...    ...   \n",
      "223  [[85, 124, 109, 91, 70, 119, 15, 16, 14, 16, 1...     331   1302   \n",
      "224  [[140, 122, 71, 106, 138, 135, 23, 13, 1, 16, ...     332   1303   \n",
      "225  [[126, 110, 76, 95, 126, 111, 79, 56, 13, 10, ...     330   1316   \n",
      "226  [[74, 69, 102, 107, 82, 59, 88, 113, 105, 60, ...     332   1311   \n",
      "227  [[99, 61, 109, 116, 99, 62, 97, 107, 123, 70, ...     329   1292   \n",
      "\n",
      "                                                padded  \\\n",
      "2    [[169, 153, 110, 125, 166, 171, 121, 130, 161,...   \n",
      "3    [[137, 107, 173, 161, 128, 109, 167, 170, 147,...   \n",
      "4    [[116, 135, 159, 175, 107, 118, 166, 169, 123,...   \n",
      "5    [[139, 111, 153, 170, 144, 111, 140, 171, 158,...   \n",
      "6    [[164, 142, 111, 164, 174, 154, 106, 141, 178,...   \n",
      "..                                                 ...   \n",
      "223  [[85, 124, 109, 91, 70, 119, 15, 16, 14, 16, 1...   \n",
      "224  [[140, 122, 71, 106, 138, 135, 23, 13, 1, 16, ...   \n",
      "225  [[126, 110, 76, 95, 126, 111, 79, 56, 13, 10, ...   \n",
      "226  [[74, 69, 102, 107, 82, 59, 88, 113, 105, 60, ...   \n",
      "227  [[99, 61, 109, 116, 99, 62, 97, 107, 123, 70, ...   \n",
      "\n",
      "                                             raw_coord  \\\n",
      "2    [[108.0, 6.0], [109.0, 6.0], [112.0, 6.0], [11...   \n",
      "3    [[58.0, 6.0], [59.0, 6.0], [121.0, 6.0], [122....   \n",
      "4    [[57.0, 6.0], [58.0, 6.0], [67.0, 6.0], [68.0,...   \n",
      "5    [[1121.0, 4.0], [1122.0, 4.0], [1123.0, 4.0], ...   \n",
      "6    [[863.0, 7.0], [864.0, 7.0], [862.0, 8.0], [86...   \n",
      "..                                                 ...   \n",
      "223  [[7.0, 0.0], [8.0, 0.0], [6.0, 1.0], [7.0, 1.0...   \n",
      "224  [[6.0, 0.0], [7.0, 0.0], [8.0, 0.0], [6.0, 1.0...   \n",
      "225  [[9.0, 0.0], [10.0, 0.0], [9.0, 1.0], [10.0, 1...   \n",
      "226  [[0.0, 7.0], [1.0, 7.0], [2.0, 7.0], [3.0, 7.0...   \n",
      "227  [[190.0, 5.0], [194.0, 5.0], [348.0, 5.0], [35...   \n",
      "\n",
      "                                          window_coord  \\\n",
      "2    [[108.0, 6.0], [109.0, 6.0], [112.0, 6.0], [11...   \n",
      "3    [[58.0, 6.0], [59.0, 6.0], [121.0, 6.0], [122....   \n",
      "4    [[57.0, 6.0], [58.0, 6.0], [67.0, 6.0], [68.0,...   \n",
      "5    [[97.0, 6.0], [98.0, 6.0], [114.0, 6.0], [115....   \n",
      "6    [[863.0, 7.0], [864.0, 7.0], [862.0, 8.0], [86...   \n",
      "..                                                 ...   \n",
      "223  [[7.0, 0.0], [8.0, 0.0], [6.0, 1.0], [7.0, 1.0...   \n",
      "224  [[6.0, 0.0], [7.0, 0.0], [8.0, 0.0], [6.0, 1.0...   \n",
      "225  [[9.0, 0.0], [10.0, 0.0], [9.0, 1.0], [10.0, 1...   \n",
      "226  [[0.0, 7.0], [1.0, 7.0], [2.0, 7.0], [3.0, 7.0...   \n",
      "227  [[190.0, 5.0], [194.0, 5.0], [348.0, 5.0], [35...   \n",
      "\n",
      "                                          mapped_coord      fmin    max_depth  \\\n",
      "2    [[0.5656934306569343, -81.81818181818184], [0....  0.375000  1350.000000   \n",
      "3    [[0.3833333333333333, -81.81818181818184], [0....  0.375000   781.818182   \n",
      "4    [[0.375, -81.81818181818184], [0.3833333333333...  0.162903   568.181818   \n",
      "5    [[0.5456204379562044, -81.81818181818184], [0....  0.366667  1350.000000   \n",
      "6    [[19.952380952380953, -77.27272727272728], [20...  0.655109  1350.000000   \n",
      "..                                                 ...       ...          ...   \n",
      "223  [[11.72972972972973, -86.36363636363637], [15....  0.100000   450.000000   \n",
      "224  [[0.1, -77.27272727272728], [0.104838709677419...  0.100000   681.818182   \n",
      "225  [[10.432432432432432, -86.36363636363637], [10...  0.100000   381.818182   \n",
      "226  [[0.1, -77.27272727272728], [0.104838709677419...  0.100000   781.818182   \n",
      "227  [[0.7153284671532847, -86.36363636363637], [0....  0.100000   454.545455   \n",
      "\n",
      "                                            mapping_Hz          mapping_km  \n",
      "2    {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "3    {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "4    {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "5    {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "6    {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "..                                                 ...                 ...  \n",
      "223  {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "224  {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "225  {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "226  {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "227  {0.1: 11, 0.25: 42, 0.5: 72, 0.75: 209, 1.0: 2...  {100: 46, 200: 68}  \n",
      "\n",
      "[152 rows x 14 columns],                                              file_name  \\\n",
      "0    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "195  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "201  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "203  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "\n",
      "                                             func_name  \\\n",
      "0    ionogram_content_extraction.extract_select_par...   \n",
      "195  ionogram_content_extraction.extract_select_par...   \n",
      "201  ionogram_content_extraction.extract_select_par...   \n",
      "203  ionogram_content_extraction.extract_select_par...   \n",
      "\n",
      "                                           subdir_name  \n",
      "0    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  \n",
      "195  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  \n",
      "201  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  \n",
      "203  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  ,                                              file_name  \\\n",
      "1    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "38   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "39   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "40   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "42   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "..                                                 ...   \n",
      "228  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "229  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "230  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "231  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "232  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...   \n",
      "\n",
      "                                             func_name  \\\n",
      "1    image_segmentation.segment_images_in_subdir.se...   \n",
      "38   image_segmentation.segment_images_in_subdir.se...   \n",
      "39   image_segmentation.segment_images_in_subdir.se...   \n",
      "40   image_segmentation.segment_images_in_subdir.se...   \n",
      "42   image_segmentation.segment_images_in_subdir.se...   \n",
      "..                                                 ...   \n",
      "228  image_segmentation.segment_images_in_subdir.se...   \n",
      "229  image_segmentation.segment_images_in_subdir.se...   \n",
      "230  image_segmentation.segment_images_in_subdir.se...   \n",
      "231  image_segmentation.segment_images_in_subdir.se...   \n",
      "232  image_segmentation.segment_images_in_subdir.se...   \n",
      "\n",
      "                                           subdir_name                 details  \n",
      "1    L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 330,width: 983  \n",
      "38   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 330,width: 748  \n",
      "39   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 360,width: 397  \n",
      "40   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 278,width: 257  \n",
      "42   L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 330,width: 817  \n",
      "..                                                 ...                     ...  \n",
      "228  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 332,width: 726  \n",
      "229  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 357,width: 442  \n",
      "230  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 333,width: 419  \n",
      "231  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 333,width: 151  \n",
      "232  L:/DATA/ISIS/ISIS_101300030772/b3_R014207773/B...  height: 273,width: 272  \n",
      "\n",
      "[77 rows x 4 columns])\n"
     ]
    }
   ],
   "source": [
    "print(process_subdirectory(SD_PATH, \"/*\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
