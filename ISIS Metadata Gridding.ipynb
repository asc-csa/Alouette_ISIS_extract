{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISIS Gridding for Metadata (in-progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a random image\n",
    "Generates and displays a random image from subdirectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:/DATA/ISIS/ISIS_101300030772\\b33_R014207877\\B1-34-64 ISIS A C-1124\\Image0072.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def gen_ran_subdir (subdir_path):\n",
    "    \"\"\"\" Generates a random subdirectory\n",
    "    Requires: \n",
    "    subdir_path: name of the path for the subdirectory\n",
    "     L:/DATA/ISIS/ISIS_101300030772/b*/B1* \"\"\"\n",
    "\n",
    "    all_subs = glob.glob(subdir_path) #creates a list of all subdirects \n",
    "    selected_sub = all_subs[random.randint(0, len(all_subs)-1)] #picks a random one from list\n",
    "    return (selected_sub)\n",
    "\n",
    "def gen_ran_img (subdir_path, img):\n",
    "    \"\"\"\" Generates a random image \"\"\"\n",
    "\n",
    "    all_img = glob.glob(subdir_path + img) #creates list of all images\n",
    "\n",
    "    selected_img = all_img[random.randint(0, len(all_img) - 1)]\n",
    "    return (selected_img)\n",
    "\n",
    "img_path = ((gen_ran_img(gen_ran_subdir(\"L:/DATA/ISIS/ISIS_101300030772/b*/B1*\"),\"/*\")))\n",
    "\n",
    "# Display\n",
    "print (img_path)\n",
    "img = mpimg.imread(img_path)\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Crop image\n",
    "# Need to crop bottom ~20%\n",
    "\n",
    "height, width = img.shape[0:2]\n",
    "\n",
    "y, x = img.shape[0], img.shape[1]\n",
    "h = int(y*0.85)\n",
    "\n",
    "crop_img = img[h:y, 0:x]\n",
    "cv2.imshow(\"cropped image\", crop_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\B1-34-57 ISIS A C-717\n",
      "L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\B1-34-57 ISIS A C-717\\Image0045.png\n"
     ]
    }
   ],
   "source": [
    "SD_PATH = gen_ran_subdir(\"L:/DATA/ISIS/ISIS_101300030772/b*/B1*\")\n",
    "I_PATH = gen_ran_img(SD_PATH, '/*')\n",
    "print ((SD_PATH))\n",
    "print (I_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From helper_functions.py\n",
    "def record_loss (df, function_name, subdir_location, columns_to_extract=['file_name'], loss_extraction=[]):\n",
    "    \"\"\"Create dataframe that records loss.\"\"\"\n",
    "\n",
    "    if len(loss_extraction) == 0:\n",
    "        #should return NA if there's an error\n",
    "        loss_extraction = df.isna().any(axis = 1)\n",
    "\n",
    "    df_loss_extraction = df[loss_extraction].copy()\n",
    "    df_loss_extraction = df_loss_extraction[columns_to_extract]\n",
    "    df_loss_extraction[\"func_name\"] = function_name\n",
    "    df_loss_extraction[\"subdir_name\"] = subdir_location\n",
    "\n",
    "    return df_loss_extraction, loss_extraction\n",
    "\n",
    "\n",
    "# location?\n",
    "def metadata_location(meta, min_count = 50, max_count = 1000):\n",
    "    \"\"\"\"Use connected component algorithm to find the location of the metadata\"\"\"\n",
    "    \n",
    "    #run algorithm on metadata section\n",
    "    _, labelled = cv2.connectedComponents(meta)\n",
    "\n",
    "    #Dictionary of label:counts\n",
    "    unique, counts = np.unique(labelled, return_counts = True)\n",
    "    dict_components = dict(zip(unique, counts))\n",
    "\n",
    "    #Remove outliers // Remove pixels not part of metadata\n",
    "    dict_subset = {}\n",
    "    dict_outlier = {}\n",
    "    for k,v, in dict_components.items():\n",
    "        if v > min_count and v < max_count:\n",
    "            dict_subset[k] = v\n",
    "        else:\n",
    "            dict_outlier[k] = v\n",
    "    \n",
    "    key_list_to_remove = list(dict_outlier.keys())\n",
    "    if len(key_list_to_remove) != 0:\n",
    "        for k in key_list_to_remove:\n",
    "            labelled[labelled == k] = 0\n",
    "    \n",
    "    return labelled\n",
    "\n",
    "#From scan2data > image_segmentation > trim_raw_metadata\n",
    "#test provided values and change if needed\n",
    "def bottomside_metadata_trimming(connected_meta, opened_meta,\n",
    "                                 h_window = 100, w_window = 700, starting_y = 0, starting_x = 15, step_size = 10, trim_if_small = 10):\n",
    "    \"\"\"Sliding window method to locate and trim bottomside metadata\"\"\"\n",
    "    \n",
    "    def sliding_window(image, starting_y, starting_x, h_window, w_window, step_size):\n",
    "        \"\"\"da sliding window\"\"\"\n",
    "        h_img, w_img = image.shape\n",
    "        for y in range(starting_y, h_img - h_window, step_size):\n",
    "            for x in range(starting_x, w_ing - w_window, step_size):\n",
    "                yield y,x,image[y:y + h_window, x:x + w_window]\n",
    "    \n",
    "    h_raw,w_raw = opened_meta.shape\n",
    "    \n",
    "    if h_window + step_size  >= h_raw:\n",
    "        h_window = h_raw -trim_if_small\n",
    "    if w_window + step_size>= w_raw:\n",
    "        w_window = w_raw -trim_if_small\n",
    "    \n",
    "    s = sliding_window(connected_meta,starting_y,starting_x,h_window,w_window,step_size)\n",
    "\n",
    "    max_window = connected_meta[starting_y:h_window+starting_y,\n",
    "                 starting_x:w_window+starting_x ]\n",
    "    max_mean = np.mean(max_window)\n",
    "    y_max= starting_y\n",
    "    x_max = starting_x\n",
    "    for y,x,window in s:\n",
    "        tmp = window\n",
    "        mean = np.mean(tmp)\n",
    "        if mean > max_mean:\n",
    "            max_window = tmp\n",
    "            max_mean  = mean\n",
    "            y_max= y\n",
    "            x_max =x\n",
    "\n",
    "    trimmed_metadata =  opened_meta[y_max:y_max+h_window,x_max:x_max+w_window]\n",
    "\n",
    "    return trimmed_metadata\n",
    "\n",
    "#From scan2data > image_segmentation > trim_raw_metadata\n",
    "def trimming_metadata(raw_metadata, opening_kernal_size = (3,3), median_kernal_size = 5):\n",
    "    \"\"\"\"Trim the rectangle containing metadata to smallest workable area.\"\"\"\n",
    "\n",
    "    try:\n",
    "        #Filtering to reduce noise\n",
    "        median_filtered_meta = cv2.medianBlur(raw_metadata, median_kernal_size)\n",
    "        \n",
    "        #Opening operation: Eroision + Dilation\n",
    "        kernal_opening = np.ones(opening_kernal_size, dtype = np.uint8)\n",
    "        opened_meta = cv2.morphologyEx(binr, cv2.MORPH_OPEN, kernel_opening, iterations = 1)\n",
    "\n",
    "        # Binarization\n",
    "        _, metadata_binary = cv2.threshold(opened_meta, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        #Run connected components algorithm\n",
    "        connected_meta = connected_components_metadata_location(metadata_binary)\n",
    "\n",
    "        trimmed_metadata = bottomside_metadata_trimming(connected_meta, metadata_binary)\n",
    "        #function from somewhere else\n",
    "\n",
    "        #Checking\n",
    "        cv2.imshow(\"test\", trimmed_metadata)\n",
    "        cv2.waitKey(0)\n",
    "        return (trimmed_metadata)\n",
    "    except:\n",
    "        return (np.nan)\n",
    "    \n",
    "\n",
    "#location?\n",
    "#function is possible not needed -- can potentially remove\n",
    "def indices_highest_bin(list_coords):\n",
    "    \"\"\"\" returns indices of most common values using binning\n",
    "    list_coords: (np.arrray)\"\"\"\n",
    "\n",
    "    nbins = 50\n",
    "    peak_threshold = 0.2\n",
    "    distance_bwtn_peaks = 30\n",
    "\n",
    "    mean_coords = np.mean(list_coords)\n",
    "    std_coords = np.std(list_coords)\n",
    "    no_outlier_coords = list_coords[np.abs(list_coords - mean_coords) < 3 * std_coords]\n",
    "\n",
    "    #Binning\n",
    "    counts, bin_edges = np.histogram(no_outlier_coords, bins=nbins)\n",
    "\n",
    "    #Detect peaks\n",
    "    counts_norm = (counts - np.min(counts)) / (np.map(counts) - np.min(counts))\n",
    "    select_peaks = find_peaks(counts_norm, distance = distance_bwtn_peaks, promience = peak_threshold)    \n",
    "\n",
    "    return select_peaks, bin_edges, counts\n",
    "\n",
    "#location? \n",
    "def extract_centroids(cut_metadata):\n",
    "    \"\"\"Takes in cut metadata and extracts centroids\n",
    "    \n",
    "    cut_metadata: np.array\"\"\"\n",
    "\n",
    "    min_pixels = 50\n",
    "    max_pixels = 1000\n",
    "\n",
    "    _, __, stats, centroids = cv2.connectedComponentsWithStats(cut_metadata, 8) \n",
    "    area_centroids = stats[:,-1]\n",
    "\n",
    "    centroids_metadata = centroids[np.logical_and(area_centroids > min_pixels, area_centroids < max_pixels)]\n",
    "    col_centroids, row_centroids = zip(*centroids_metadata)\n",
    "\n",
    "    #Round to nearest integer\n",
    "    col_centroids = list(map(round, col_centroids))\n",
    "    row_centroids = list(map(round, row_centroids))\n",
    "\n",
    "    return col_centroids, row_centroids\n",
    "\n",
    "#From scan2data > image_segmentation > extract_ionogram_from_scan\n",
    "#For segment_metadata\n",
    "def limits_ionogram(raw_img, row_or_col, starting_index_col = 15):\n",
    "\n",
    "    mean_values = np.mean(raw_img, row_or_col)\n",
    "\n",
    "    #normalize mean\n",
    "    norm_mean = (mean_values - np.min(mean_values)) / np.max(mean_values)\n",
    "    thresh = np.mean(norm_mean)\n",
    "\n",
    "    if row_or_col == 0:\n",
    "        #Protect against scans that includes cuts from another ionogram\n",
    "        limits = [i for i, mean in enumerate(norm_mean) if mean > thresh and i > starting_index_col]\n",
    "    else:\n",
    "        limits = [i for i, mean in enumerate(norm_mean) if mean > thresh]\n",
    "\n",
    "    return limits[0], limits[-1]\n",
    "\n",
    "\n",
    "#From scan2data > image_segmentation > extract_ionogram_from_scan\n",
    "# For segment_metadata\n",
    "def extract_ionogram(raw_img_array):\n",
    "    \"\"\"\"this function is here for now to get limits of ionogram. \n",
    "    can later be changed to include ionogram graph\"\"\"\n",
    "    try:\n",
    "\n",
    "    #Extract coordinate delimiting the graph\n",
    "        x_left, x_right = limits_ionogram(raw_img_array, 0)\n",
    "        y_upper, y_lower = limits_ionogram(raw_img_array, 1)\n",
    "\n",
    "        limits = [x_left, x_right, y_upper, y_lower]\n",
    "        return (limits)\n",
    "    except:\n",
    "        return ([])\n",
    "\n",
    "\n",
    "#From scan2data > image_segmentation > extract_metadata_from_scan\n",
    "def extract_metadata (raw_img, limits_iono):\n",
    "    \"\"\"Extract metadata from raw scanned image and return coordinates delimiting its limits\"\"\"\n",
    "    print (\"these are limits\",limits_iono)\n",
    "    #Limits for ionogram\n",
    "    x_left_lim = limits_iono[0][0]\n",
    "    x_right_lim = limits_iono[0][1]\n",
    "    y_upper_lim = limits_iono[0][2] \n",
    "    y_lower_lim = limits_iono[0][3]\n",
    "\n",
    "    #Extract retangular block below** ionogram\n",
    "    rect_left = raw_img[:,0:x_left_lim]\n",
    "    rect_right = raw_img[:,x_right_lim::]\n",
    "    rect_top = raw_img[0:y_upper_lim, :]\n",
    "    rect_bottom = raw_img[y_lower_lim::,:]\n",
    "\n",
    "    #Assumption: the location of the metadata will correspond to rectangle with the highest area\n",
    "    rect_list = [rect_left, rect_right, rect_top, rect_bottom]\n",
    "    rect_areas = [rect.shape[0] * rect.shape[1] for rect in rect_list]\n",
    "    dict_mapping_meta = {0:'left', 1:\"right\", 2:\"top\", 3:'bottom'}\n",
    "\n",
    "    type_metadata_idx = np.argmax(rect_areas)\n",
    "    raw_metadata = rect_list[type_metadata_idx]\n",
    "    type_metadata = dict_mapping_meta[type_metadata_idx]\n",
    "\n",
    "    return (type_metadata, raw_metadata)\n",
    "\n",
    "\n",
    "#From scan2data> image_segmentation > segment_images_in_subdir.py\n",
    "#some variables here are not necessary and can be removed, ie. height, width...\n",
    "def segment_metadata(subdir_location, regex_img, min_bottom_height = 25, cutoff_width=300, cutoff_height=150):\n",
    "    \"\"\"Should only segment metadata. Can be adjusted to include ionogram. \"\"\"\n",
    "    regex_raw_image =  SD_PATH + (\"/*\")\n",
    "    print (\"the raw images path is:\", regex_raw_image)\n",
    "    list_images = glob.glob(regex_raw_image)\n",
    "    \n",
    "    #Dataframe is processing\n",
    "    df_img = pd.DataFrame(data = {\"file_name\": list_images})\n",
    "    #Read each image in a 2D UTF-8 grayscale array\n",
    "    df_img[\"raw\"] = df_img['file_name'].map(lambda file_name: cv2.imread(file_name, 0))\n",
    "\n",
    "    \n",
    "    # Extract ionogram and coordinates delimiting its limits\n",
    "    df_img['limits']= list(zip(df_img['raw'].map(lambda raw_img: extract_ionogram(raw_img)))) \n",
    "    print (\"dataframe with limits\", df_img)\n",
    "    # Record the files whose ionogram extraction was not successful\n",
    "    #df_loss_ion_extraction, loss_ion_extraction = record_loss(df_img,'image_segmentation.extract_ionogram_from_scan.extract_ionogram',subdir_location)\n",
    "    \n",
    "    #Raw metadata\n",
    "    df_img['metadata_type'], df_img['raw_metadata'] = zip(*df_img.apply(lambda row: extract_metadata(row['raw'], row['limits']), 1)) ### this guy\n",
    "    #extract_metadata is function from extract_metadata_from_scan\n",
    "\n",
    "    # There should be no metadata on left and top, especially after flipping\n",
    "    outlier_metadata_location = np.any([df_img['metadata_type'] == 'right',df_img['metadata_type']=='top'],axis=0)\n",
    "    df_outlier_metadata_location ,_ =  record_loss(df_img,'image_segmentation.segment_images_in_subdir.segment_images: metadata not on left or bottom',subdir_location,\n",
    "                                         ['file_name','metadata_type'],outlier_metadata_location )\n",
    "    \n",
    "    if not df_outlier_metadata_location.empty:\n",
    "        df_outlier_metadata_location['details'] = df_outlier_metadata_location.apply(lambda row: str(row['metadata_type']),1)\n",
    "        df_outlier_metadata_location = df_outlier_metadata_location[['file_name','func_name','subdir_name','details']]\n",
    "    else:\n",
    "        df_outlier_metadata_location = df_outlier_metadata_location[['file_name','func_name','subdir_name']]\n",
    "    \n",
    "    # Remove loss from detected metadata not being on the left or bottom\n",
    "    df_img = df_img[~outlier_metadata_location]\n",
    "\n",
    "    #Trimmed metadata\n",
    "    df_img['trimmed_metadata'] = df_img.apply(lambda row: trimming_metadata(row['raw_metadata'], row['metadata_type']), 1)\n",
    "    df_loss_trim, loss_trim = record_loss(df_img, 'image_segmentation.trim_raw_metadata.ntrimming_metadata', subdir_location)\n",
    "    #trimming_metadata is a function from trim_raw_metadata\n",
    "    #record_loss is a function from helper_functions\n",
    "\n",
    "    df_img = df_img[~loss_trim]\n",
    "\n",
    "    # Check if metadata too small\n",
    "    df_img['meta_height'],df_img['meta_width'] = zip(*df_img['trimmed_metadata'].map(lambda array_pixels: array_pixels.shape))\n",
    "    outlier_size_metadata = np.logical_or(np.logical_and(df_img['metadata_type'] == 'left', \n",
    "                                                      df_img['meta_width'] < min_leftside_meta_width),\n",
    "                                       np.logical_and(df_img['metadata_type'] == 'bottom', \n",
    "                                                      df_img['meta_height'] < min_bottomside_meta_height)) ### CURRENT ISSUE        \n",
    "        \n",
    "    df_outlier_metadata_size, _ = record_loss(df_img,'image_segmentation.segment_images_in_subdir.segment_images: metadata size outlier',subdir_location,\n",
    "                                           ['file_name','metadata_type','meta_height','meta_width'],outlier_size_metadata)\n",
    "\n",
    "    if not df_outlier_metadata_size.empty:\n",
    "        df_outlier_metadata_size['details'] = df_outlier_metadata_size.apply(lambda row: row['metadata_type'] + '_height: ' + \\\n",
    "                                                    str(row['meta_height'])+',width: ' + str(row['meta_width']),1)\n",
    "        df_outlier_metadata_size = df_outlier_metadata_size[['file_name','func_name','subdir_name','details']]\n",
    "        \n",
    "    else:\n",
    "        df_outlier_metadata_size = df_outlier_metadata_size[['file_name','func_name','subdir_name']]\n",
    "    \n",
    "    # Remove files whose metadata too small\n",
    "    df_img = df_img[~outlier_size_metadata]\n",
    "    \n",
    "    \n",
    "    # Dataframe recording loss from programming errors\n",
    "    df_loss = pd.concat([df_loss_ion_extraction,df_loss_trim])\n",
    "    \n",
    "    # Dataframe recording loss from various filters i.e. metadata too small, ionogram too small/big\n",
    "    df_outlier = pd.concat([df_outlier_ionogram,df_outlier_metadata_location,df_outlier_metadata_size])\n",
    "\n",
    "    return df_img,  df_loss, df_outlier\n",
    "# function can also return df_loss, df_outlier\n",
    "\n",
    "#From scan2data > metadata_translation > translate_leftside_metadata.py\n",
    "def get_bottomside_metadata (df_img, subdir_location, kernal_size =(1, 1)):\n",
    "    \"\"\"Reads the metadata (finally)\"\"\"\n",
    "\n",
    "    kernel_dilation = np.ones(kernal_size, np.uint8)\n",
    "\n",
    "    df_img['dilated_metadata'] = df_img['trimmed_metadata'].map(\n",
    "        lambda trimmed_meta: cv2.dilate(trimmed_meta, kernel_dilation))\n",
    "    df_img['x_centroids'], df_img['y_centroids'], df_img['is_dot'] = zip(\n",
    "        *df_img.apply(lambda row: extract_centroids(row['dilated_metadata'], row['file_name']), 1))\n",
    "    df_loss_centroids_extraction, loss_centroids_extraction = record_loss(df_img,\n",
    "                                                                          'metadata_translation.determine_metadata_grid_mapping.extract_centroids_',\n",
    "                                                                          subdir_location)\n",
    "    # extract_centroids and record_loss are two other functions \n",
    "\n",
    "    # Remove files where the extraction didn't work\n",
    "    df_img = df_img[~loss_centroids_extraction]\n",
    "    # ^removes them from the main dataframe\n",
    "    df_num_subset = df_img[np.invert(np.array(df_img['is_data']))]\n",
    "\n",
    "    list_x_digit = list(chain(*df_num_subset['x_centroids'].tolist()))\n",
    "    list_y_digit = list(chain(*df_num_subset['y_centroids'].tolist()))\n",
    "    dict_mapping, dict_hist = get_leftside_metadata_grid_mapping(list_x_dot, list_y_dot, list_x_digit, list_y_digit,\n",
    "                                                                 subdir_location)\n",
    "\n",
    "    # Determine the value of metadata based on the mappings\n",
    "    df_img['dict_metadata'] = df_img.apply(lambda row:\n",
    "                                           map_coord_to_metadata(row['x_centroids'], row['y_centroids'],\n",
    "                                                                 dict_mapping['dict_cat_dot'],\n",
    "                                                                 dict_mapping['dict_num_dot']) if row['is_dot']\n",
    "                                           else map_coord_to_metadata(row['x_centroids'], row['y_centroids'],\n",
    "                                                                      dict_mapping['dict_cat_digit'],\n",
    "                                                                      dict_mapping['dict_num_digit']), 1)\n",
    "    df_loss_mapping, loss_mapping = record_loss(df_img,\n",
    "                                                'metadata_translation.translate_leftside_metadata.map_coord_to_metadata',\n",
    "                                                subdir_location)\n",
    "    df_img = df_img[~loss_mapping]\n",
    "\n",
    "    df_loss = pd.concat([df_loss_centroids_extraction, df_loss_mapping])\n",
    "\n",
    "    return df_img, df_loss, dict_mapping, dict_hist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the raw images path is: L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\B1-34-57 ISIS A C-717/*\n",
      "dataframe with limits                                              file_name  \\\n",
      "0    L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "1    L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "2    L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "3    L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "4    L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "..                                                 ...   \n",
      "429  L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "430  L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "431  L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "432  L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "433  L:/DATA/ISIS/ISIS_101300030772\\b17_R014207703\\...   \n",
      "\n",
      "                                                   raw                  limits  \n",
      "0    [[46, 32, 47, 41, 39, 51, 40, 54, 39, 55, 45, ...  ([18, 1094, 20, 340],)  \n",
      "1    [[68, 60, 62, 60, 66, 48, 46, 57, 64, 60, 61, ...  ([16, 1093, 20, 340],)  \n",
      "2    [[60, 69, 59, 57, 59, 86, 57, 58, 56, 51, 47, ...  ([16, 1083, 20, 341],)  \n",
      "3    [[51, 52, 49, 51, 47, 57, 63, 60, 51, 61, 63, ...  ([16, 1090, 20, 340],)  \n",
      "4    [[39, 55, 54, 52, 51, 63, 35, 53, 45, 54, 51, ...  ([16, 1090, 20, 340],)  \n",
      "..                                                 ...                     ...  \n",
      "429  [[42, 45, 54, 45, 57, 60, 52, 48, 51, 45, 49, ...   ([16, 276, 22, 343],)  \n",
      "430  [[40, 32, 34, 24, 35, 31, 28, 34, 44, 32, 33, ...   ([16, 357, 21, 395],)  \n",
      "431  [[12, 8, 10, 8, 12, 5, 6, 4, 9, 5, 12, 11, 12,...   ([69, 341, 57, 316],)  \n",
      "432  [[48, 57, 50, 50, 50, 46, 57, 56, 54, 51, 47, ...   ([16, 291, 26, 343],)  \n",
      "433  [[23, 1, 1, 2, 2, 3, 1, 2, 3, 2, 2, 2, 1, 1, 4...   ([74, 354, 58, 324],)  \n",
      "\n",
      "[434 rows x 3 columns]\n",
      "these are limits ([18, 1094, 20, 340],)\n",
      "these are limits ([16, 1093, 20, 340],)\n",
      "these are limits ([16, 1083, 20, 341],)\n",
      "these are limits ([16, 1090, 20, 340],)\n",
      "these are limits ([16, 1090, 20, 340],)\n",
      "these are limits ([16, 1090, 20, 340],)\n",
      "these are limits ([16, 1090, 20, 340],)\n",
      "these are limits ([16, 1090, 20, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1096, 19, 340],)\n",
      "these are limits ([17, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1076, 19, 340],)\n",
      "these are limits ([16, 1098, 19, 340],)\n",
      "these are limits ([16, 1098, 19, 340],)\n",
      "these are limits ([16, 1090, 19, 340],)\n",
      "these are limits ([17, 1082, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1090, 19, 340],)\n",
      "these are limits ([17, 1084, 19, 340],)\n",
      "these are limits ([16, 1084, 19, 340],)\n",
      "these are limits ([16, 622, 171, 342],)\n",
      "these are limits ([16, 346, 19, 392],)\n",
      "these are limits ([106, 346, 19, 340],)\n",
      "these are limits ([16, 342, 19, 340],)\n",
      "these are limits ([16, 333, 19, 340],)\n",
      "these are limits ([18, 340, 19, 340],)\n",
      "these are limits ([68, 351, 51, 308],)\n",
      "these are limits ([66, 343, 57, 318],)\n",
      "these are limits ([16, 787, 23, 344],)\n",
      "these are limits ([16, 1089, 17, 338],)\n",
      "these are limits ([16, 1089, 17, 338],)\n",
      "these are limits ([16, 1081, 17, 337],)\n",
      "these are limits ([16, 1081, 17, 338],)\n",
      "these are limits ([16, 1085, 17, 338],)\n",
      "these are limits ([16, 1085, 17, 337],)\n",
      "these are limits ([16, 1085, 17, 337],)\n",
      "these are limits ([16, 1085, 17, 337],)\n",
      "these are limits ([16, 1085, 21, 342],)\n",
      "these are limits ([16, 1085, 21, 342],)\n",
      "these are limits ([16, 1091, 21, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([17, 1090, 21, 342],)\n",
      "these are limits ([16, 520, 19, 340],)\n",
      "these are limits ([16, 352, 183, 344],)\n",
      "these are limits ([19, 352, 174, 344],)\n",
      "these are limits ([19, 383, 178, 344],)\n",
      "these are limits ([16, 218, 21, 342],)\n",
      "these are limits ([147, 343, 17, 337],)\n",
      "these are limits ([16, 333, 19, 340],)\n",
      "these are limits ([75, 343, 52, 314],)\n",
      "these are limits ([17, 1095, 19, 340],)\n",
      "these are limits ([16, 1095, 19, 340],)\n",
      "these are limits ([16, 1091, 19, 340],)\n",
      "these are limits ([16, 1091, 19, 340],)\n",
      "these are limits ([16, 1079, 19, 340],)\n",
      "these are limits ([16, 1109, 19, 340],)\n",
      "these are limits ([16, 1073, 19, 339],)\n",
      "these are limits ([16, 1103, 19, 339],)\n",
      "these are limits ([16, 1091, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1087, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1079, 19, 339],)\n",
      "these are limits ([16, 1079, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1092, 19, 339],)\n",
      "these are limits ([16, 1089, 19, 339],)\n",
      "these are limits ([17, 1089, 19, 340],)\n",
      "these are limits ([16, 1089, 19, 339],)\n",
      "these are limits ([16, 1089, 19, 339],)\n",
      "these are limits ([16, 1083, 19, 339],)\n",
      "these are limits ([16, 1083, 19, 339],)\n",
      "these are limits ([16, 1083, 19, 339],)\n",
      "these are limits ([16, 1083, 19, 339],)\n",
      "these are limits ([17, 849, 19, 339],)\n",
      "these are limits ([22, 433, 159, 340],)\n",
      "these are limits ([16, 115, 18, 377],)\n",
      "these are limits ([64, 340, 57, 321],)\n",
      "these are limits ([20, 1106, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([17, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1072, 19, 339],)\n",
      "these are limits ([17, 1072, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1082, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 614, 19, 339],)\n",
      "these are limits ([16, 471, 162, 342],)\n",
      "these are limits ([29, 549, 146, 340],)\n",
      "these are limits ([16, 432, 151, 340],)\n",
      "these are limits ([24, 371, 134, 340],)\n",
      "these are limits ([16, 353, 19, 378],)\n",
      "these are limits ([85, 353, 17, 337],)\n",
      "these are limits ([16, 347, 19, 340],)\n",
      "these are limits ([16, 350, 19, 339],)\n",
      "these are limits ([17, 294, 19, 339],)\n",
      "these are limits ([69, 344, 51, 314],)\n",
      "these are limits ([18, 897, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1086, 19, 339],)\n",
      "these are limits ([16, 1084, 19, 339],)\n",
      "these are limits ([16, 1084, 19, 339],)\n",
      "these are limits ([16, 1084, 19, 339],)\n",
      "these are limits ([16, 1084, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1080, 19, 339],)\n",
      "these are limits ([16, 1084, 19, 339],)\n",
      "these are limits ([119, 1084, 19, 339],)\n",
      "these are limits ([118, 1084, 19, 339],)\n",
      "these are limits ([118, 1084, 19, 339],)\n",
      "these are limits ([116, 1084, 19, 339],)\n",
      "these are limits ([115, 1084, 19, 339],)\n",
      "these are limits ([112, 1081, 19, 339],)\n",
      "these are limits ([110, 1078, 19, 339],)\n",
      "these are limits ([114, 1078, 19, 339],)\n",
      "these are limits ([115, 1078, 19, 339],)\n",
      "these are limits ([118, 1078, 19, 339],)\n",
      "these are limits ([48, 1078, 19, 339],)\n",
      "these are limits ([71, 1088, 19, 339],)\n",
      "these are limits ([120, 1088, 19, 339],)\n",
      "these are limits ([114, 1084, 19, 339],)\n",
      "these are limits ([52, 1078, 19, 339],)\n",
      "these are limits ([16, 1080, 17, 337],)\n",
      "these are limits ([64, 1080, 17, 337],)\n",
      "these are limits ([79, 1080, 17, 337],)\n",
      "these are limits ([16, 1080, 17, 337],)\n",
      "these are limits ([16, 1080, 17, 337],)\n",
      "these are limits ([16, 1080, 16, 337],)\n",
      "these are limits ([16, 1072, 17, 337],)\n",
      "these are limits ([16, 1072, 17, 337],)\n",
      "these are limits ([16, 471, 17, 338],)\n",
      "these are limits ([174, 368, 17, 366],)\n",
      "these are limits ([68, 341, 54, 317],)\n",
      "these are limits ([16, 868, 24, 345],)\n",
      "these are limits ([69, 348, 56, 323],)\n",
      "these are limits ([16, 123, 23, 382],)\n",
      "these are limits ([93, 368, 21, 342],)\n",
      "these are limits ([18, 368, 21, 343],)\n",
      "these are limits ([16, 334, 21, 342],)\n",
      "these are limits ([18, 294, 19, 340],)\n",
      "these are limits ([68, 344, 53, 319],)\n",
      "these are limits ([16, 361, 18, 379],)\n",
      "these are limits ([66, 344, 59, 322],)\n",
      "these are limits ([36, 177, 18, 340],)\n",
      "these are limits ([71, 347, 58, 320],)\n",
      "these are limits ([16, 214, 19, 341],)\n",
      "these are limits ([16, 355, 19, 393],)\n",
      "these are limits ([25, 351, 17, 338],)\n",
      "these are limits ([16, 352, 17, 338],)\n",
      "these are limits ([16, 343, 17, 338],)\n",
      "these are limits ([18, 303, 17, 338],)\n",
      "these are limits ([70, 340, 54, 324],)\n",
      "these are limits ([16, 347, 17, 338],)\n",
      "these are limits ([17, 350, 17, 338],)\n",
      "these are limits ([17, 107, 19, 340],)\n",
      "these are limits ([70, 348, 54, 323],)\n",
      "these are limits ([16, 142, 221, 343],)\n",
      "these are limits ([68, 338, 56, 318],)\n",
      "these are limits ([16, 166, 31, 337],)\n",
      "these are limits ([16, 367, 14, 389],)\n",
      "these are limits ([133, 465, 52, 314],)\n",
      "these are limits ([160, 367, 17, 338],)\n",
      "these are limits ([17, 359, 17, 338],)\n",
      "these are limits ([16, 352, 17, 338],)\n",
      "these are limits ([70, 346, 57, 318],)\n",
      "these are limits ([172, 321, 198, 389],)\n",
      "these are limits ([16, 1051, 21, 342],)\n",
      "these are limits ([16, 1094, 21, 342],)\n",
      "these are limits ([16, 1094, 21, 342],)\n",
      "these are limits ([17, 1082, 21, 342],)\n",
      "these are limits ([16, 1082, 21, 342],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([17, 1092, 19, 340],)\n",
      "these are limits ([16, 1092, 19, 340],)\n",
      "these are limits ([16, 1092, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([17, 1091, 17, 338],)\n",
      "these are limits ([16, 1088, 17, 338],)\n",
      "these are limits ([16, 1091, 17, 338],)\n",
      "these are limits ([16, 1085, 17, 338],)\n",
      "these are limits ([16, 1085, 17, 338],)\n",
      "these are limits ([16, 1101, 17, 338],)\n",
      "these are limits ([155, 1091, 17, 338],)\n",
      "these are limits ([153, 1086, 17, 338],)\n",
      "these are limits ([148, 1082, 17, 338],)\n",
      "these are limits ([141, 1082, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([19, 1086, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([16, 1086, 17, 338],)\n",
      "these are limits ([160, 1086, 17, 338],)\n",
      "these are limits ([166, 1086, 17, 338],)\n",
      "these are limits ([177, 1086, 17, 338],)\n",
      "these are limits ([38, 668, 138, 338],)\n",
      "these are limits ([164, 355, 17, 338],)\n",
      "these are limits ([69, 341, 53, 319],)\n",
      "these are limits ([17, 1016, 18, 339],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1099, 19, 340],)\n",
      "these are limits ([16, 1070, 19, 340],)\n",
      "these are limits ([16, 1070, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1082, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1087, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1083, 19, 340],)\n",
      "these are limits ([16, 1075, 19, 340],)\n",
      "these are limits ([16, 1075, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1094, 19, 340],)\n",
      "these are limits ([16, 1095, 19, 340],)\n",
      "these are limits ([16, 1075, 19, 340],)\n",
      "these are limits ([16, 1075, 19, 340],)\n",
      "these are limits ([16, 1075, 19, 340],)\n",
      "these are limits ([16, 791, 19, 340],)\n",
      "these are limits ([19, 421, 19, 340],)\n",
      "these are limits ([16, 960, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1090, 19, 340],)\n",
      "these are limits ([16, 1081, 19, 340],)\n",
      "these are limits ([16, 1084, 19, 340],)\n",
      "these are limits ([16, 1084, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 596, 19, 340],)\n",
      "these are limits ([16, 458, 157, 341],)\n",
      "these are limits ([16, 688, 151, 341],)\n",
      "these are limits ([21, 455, 109, 340],)\n",
      "these are limits ([82, 364, 19, 340],)\n",
      "these are limits ([66, 347, 55, 317],)\n",
      "these are limits ([16, 435, 123, 343],)\n",
      "these are limits ([16, 1048, 22, 343],)\n",
      "these are limits ([16, 1084, 22, 343],)\n",
      "these are limits ([16, 1090, 22, 342],)\n",
      "these are limits ([16, 1090, 22, 342],)\n",
      "these are limits ([16, 1090, 22, 342],)\n",
      "these are limits ([16, 1088, 22, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([16, 1089, 21, 342],)\n",
      "these are limits ([16, 1084, 21, 342],)\n",
      "these are limits ([16, 1084, 22, 342],)\n",
      "these are limits ([16, 1084, 22, 342],)\n",
      "these are limits ([16, 1084, 21, 342],)\n",
      "these are limits ([16, 1088, 21, 342],)\n",
      "these are limits ([16, 1088, 22, 342],)\n",
      "these are limits ([16, 1088, 22, 342],)\n",
      "these are limits ([16, 1088, 21, 342],)\n",
      "these are limits ([16, 1085, 21, 342],)\n",
      "these are limits ([16, 1087, 22, 342],)\n",
      "these are limits ([16, 1088, 22, 342],)\n",
      "these are limits ([16, 1087, 21, 342],)\n",
      "these are limits ([16, 1080, 21, 342],)\n",
      "these are limits ([17, 1079, 21, 342],)\n",
      "these are limits ([16, 1080, 21, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([16, 1089, 21, 342],)\n",
      "these are limits ([16, 1089, 21, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([16, 1090, 21, 342],)\n",
      "these are limits ([16, 1064, 21, 342],)\n",
      "these are limits ([16, 1082, 21, 342],)\n",
      "these are limits ([16, 1088, 21, 342],)\n",
      "these are limits ([16, 1088, 21, 342],)\n",
      "these are limits ([16, 1087, 15, 336],)\n",
      "these are limits ([16, 1088, 20, 340],)\n",
      "these are limits ([16, 1227, 20, 340],)\n",
      "these are limits ([17, 1240, 137, 341],)\n",
      "these are limits ([71, 344, 56, 317],)\n",
      "these are limits ([17, 413, 150, 342],)\n",
      "these are limits ([16, 1056, 20, 341],)\n",
      "these are limits ([17, 1081, 20, 341],)\n",
      "these are limits ([16, 1093, 20, 340],)\n",
      "these are limits ([16, 1091, 20, 340],)\n",
      "these are limits ([16, 1094, 20, 340],)\n",
      "these are limits ([16, 1079, 20, 340],)\n",
      "these are limits ([16, 1082, 20, 340],)\n",
      "these are limits ([16, 1084, 20, 340],)\n",
      "these are limits ([17, 1084, 20, 340],)\n",
      "these are limits ([16, 1084, 20, 340],)\n",
      "these are limits ([16, 1088, 20, 340],)\n",
      "these are limits ([16, 1087, 20, 340],)\n",
      "these are limits ([16, 1088, 20, 340],)\n",
      "these are limits ([16, 1088, 20, 340],)\n",
      "these are limits ([16, 1087, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1068, 19, 340],)\n",
      "these are limits ([16, 1112, 19, 340],)\n",
      "these are limits ([18, 1086, 19, 340],)\n",
      "these are limits ([18, 1085, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([18, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 20, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([18, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 278, 19, 369],)\n",
      "these are limits ([16, 368, 19, 378],)\n",
      "these are limits ([18, 347, 19, 340],)\n",
      "these are limits ([72, 359, 61, 321],)\n",
      "these are limits ([74, 307, 0, 397],)\n",
      "these are limits ([20, 1207, 22, 343],)\n",
      "these are limits ([16, 1072, 22, 343],)\n",
      "these are limits ([16, 1072, 22, 342],)\n",
      "these are limits ([16, 1072, 22, 342],)\n",
      "these are limits ([16, 1086, 22, 342],)\n",
      "these are limits ([16, 1086, 22, 342],)\n",
      "these are limits ([16, 1086, 21, 342],)\n",
      "these are limits ([16, 1086, 21, 342],)\n",
      "these are limits ([16, 1086, 22, 342],)\n",
      "these are limits ([16, 1085, 22, 342],)\n",
      "these are limits ([16, 1086, 22, 342],)\n",
      "these are limits ([16, 1086, 22, 342],)\n",
      "these are limits ([16, 1086, 20, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 1072, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1078, 19, 340],)\n",
      "these are limits ([16, 1090, 19, 340],)\n",
      "these are limits ([16, 1090, 19, 340],)\n",
      "these are limits ([16, 1080, 20, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1080, 19, 340],)\n",
      "these are limits ([16, 1112, 19, 340],)\n",
      "these are limits ([18, 1088, 19, 340],)\n",
      "these are limits ([16, 1088, 19, 340],)\n",
      "these are limits ([16, 1076, 19, 340],)\n",
      "these are limits ([16, 1076, 19, 340],)\n",
      "these are limits ([16, 1092, 19, 340],)\n",
      "these are limits ([16, 1092, 19, 340],)\n",
      "these are limits ([16, 1073, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([16, 1086, 19, 340],)\n",
      "these are limits ([107, 1086, 19, 340],)\n",
      "these are limits ([115, 1077, 19, 340],)\n",
      "these are limits ([118, 1084, 19, 340],)\n",
      "these are limits ([122, 1084, 19, 340],)\n",
      "these are limits ([117, 823, 19, 340],)\n",
      "these are limits ([16, 383, 197, 344],)\n",
      "these are limits ([16, 206, 24, 340],)\n",
      "these are limits ([71, 344, 61, 327],)\n",
      "these are limits ([16, 126, 22, 343],)\n",
      "these are limits ([16, 357, 20, 341],)\n",
      "these are limits ([64, 333, 55, 322],)\n",
      "these are limits ([18, 308, 20, 341],)\n",
      "these are limits ([256, 364, 20, 392],)\n",
      "these are limits ([16, 361, 20, 340],)\n",
      "these are limits ([18, 348, 20, 341],)\n",
      "these are limits ([16, 362, 18, 339],)\n",
      "these are limits ([16, 52, 18, 339],)\n",
      "these are limits ([70, 339, 56, 326],)\n",
      "these are limits ([16, 273, 22, 343],)\n",
      "these are limits ([16, 359, 22, 395],)\n",
      "these are limits ([85, 359, 22, 343],)\n",
      "these are limits ([74, 343, 56, 322],)\n",
      "these are limits ([16, 330, 22, 343],)\n",
      "these are limits ([174, 361, 20, 369],)\n",
      "these are limits ([73, 353, 56, 320],)\n",
      "these are limits ([16, 294, 22, 343],)\n",
      "these are limits ([238, 354, 22, 381],)\n",
      "these are limits ([16, 354, 22, 343],)\n",
      "these are limits ([16, 350, 20, 341],)\n",
      "these are limits ([71, 340, 56, 321],)\n",
      "these are limits ([16, 276, 22, 343],)\n",
      "these are limits ([16, 357, 21, 395],)\n",
      "these are limits ([69, 341, 57, 316],)\n",
      "these are limits ([16, 291, 26, 343],)\n",
      "these are limits ([74, 354, 58, 324],)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\spunchiwickrama\\ISIS_I\\Alouette_extract\\ISIS Metadata Gridding.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     df_all_loss \u001b[39m=\u001b[39m df_all_loss\u001b[39m.\u001b[39mappend(df_loss_coord)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df_processed, df_all_loss, df_outlier\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m (process_subdir(SD_PATH, \u001b[39m'\u001b[39;49m\u001b[39m/*\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mG:/spunchiwickrama/ISIS_I/output\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;32mg:\\spunchiwickrama\\ISIS_I\\Alouette_extract\\ISIS Metadata Gridding.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform raw scanned images in subdir into information\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#Run segment_images on subdir\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_img, df_loss, df_outlier \u001b[39m=\u001b[39m segment_metadata(subdir_path, regex_images)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#Translate metadata on bottom\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_img_bottom \u001b[39m=\u001b[39m df_img[df_img[\u001b[39m'\u001b[39m\u001b[39mmetadata_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;32mg:\\spunchiwickrama\\ISIS_I\\Alouette_extract\\ISIS Metadata Gridding.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=264'>265</a>\u001b[0m df_img \u001b[39m=\u001b[39m df_img[\u001b[39m~\u001b[39mloss_trim]\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=266'>267</a>\u001b[0m \u001b[39m# Check if metadata too small\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=267'>268</a>\u001b[0m df_img[\u001b[39m'\u001b[39m\u001b[39mmeta_height\u001b[39m\u001b[39m'\u001b[39m],df_img[\u001b[39m'\u001b[39m\u001b[39mmeta_width\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mdf_img[\u001b[39m'\u001b[39m\u001b[39mtrimmed_metadata\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m array_pixels: array_pixels\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=268'>269</a>\u001b[0m outlier_size_metadata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_or(np\u001b[39m.\u001b[39mlogical_and(df_img[\u001b[39m'\u001b[39m\u001b[39mmetadata_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=269'>270</a>\u001b[0m                                                   df_img[\u001b[39m'\u001b[39m\u001b[39mmeta_width\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m min_leftside_meta_width),\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=270'>271</a>\u001b[0m                                    np\u001b[39m.\u001b[39mlogical_and(df_img[\u001b[39m'\u001b[39m\u001b[39mmetadata_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=271'>272</a>\u001b[0m                                                   df_img[\u001b[39m'\u001b[39m\u001b[39mmeta_height\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m min_bottomside_meta_height))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=273'>274</a>\u001b[0m df_outlier_metadata_size, _ \u001b[39m=\u001b[39m record_loss(df_img,\u001b[39m'\u001b[39m\u001b[39mimage_segmentation.segment_images_in_subdir.segment_images: metadata size outlier\u001b[39m\u001b[39m'\u001b[39m,subdir_location,\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/spunchiwickrama/ISIS_I/Alouette_extract/ISIS%20Metadata%20Gridding.ipynb#W6sZmlsZQ%3D%3D?line=274'>275</a>\u001b[0m                                        [\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmetadata_type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmeta_height\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmeta_width\u001b[39m\u001b[39m'\u001b[39m],outlier_size_metadata)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "#From process_directory.py\n",
    "def process_subdir(subdir_path, regex_images, output_folder_if_pickle,\n",
    "                   to_pickle=True):\n",
    "    \"\"\"Transform raw scanned images in subdir into information\"\"\"\n",
    "\n",
    "    #Run segment_images on subdir\n",
    "    df_img, df_loss, df_outlier = segment_metadata(subdir_path, regex_images)\n",
    "\n",
    "    #Translate metadata on bottom\n",
    "    df_img_bottom = df_img[df_img['metadata_type'] == 'bottom']\n",
    "\n",
    "    df_img, df_loss_meta, dict_mapping, dict_hist = get_bottonside_metadata(df_img, subdir_path)\n",
    "    #get_bottomside_metadata is another function\n",
    "    df_all_loss = df_loss\n",
    "\n",
    "    #pickle \n",
    "    if to_pickle:\n",
    "        start, subdir_name = ntpath.split(subdir_path[:-1])\n",
    "        start, dir_name = ntpath.split(start)\n",
    "        df_processed.to_pickle(os.pardir + '/pickle/' + str(dir_name) + '_' + str(subdir_name) + '.pkl')\n",
    "\n",
    "    df_all_loss = df_all_loss.append(df_loss_coord)\n",
    "\n",
    "    return df_processed, df_all_loss, df_outlier\n",
    "\n",
    "print (process_subdir(SD_PATH, '/*', \"G:/spunchiwickrama/ISIS_I/output\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonV31013",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
