{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180d0595",
   "metadata": {},
   "source": [
    "# Process Subdirectories II\n",
    "\n",
    "#### Updated: May 12, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63f384",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39304129",
   "metadata": {},
   "source": [
    "Run for continuous processing of subdirectories, concurrent with the downloading of subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a5f40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e6163cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628732b",
   "metadata": {},
   "source": [
    "Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83835627",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = 1 \n",
    "user = 'Rav Super' + str(instance)\n",
    "process_on_VDI = True\n",
    "wait = 2 #in minutes\n",
    "stop_loop_threshold = 2640 #max while loops to prevent infinite loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9697506",
   "metadata": {},
   "source": [
    "Set directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42031944",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir_local = 'G:/rnaidoo/Alouette_I/SuperVDI' + str(instance) + '/BATCH_II_Run1/'\n",
    "rootDir_L = 'L:/DATA/Alouette_I/BATCH_II_Run1/'\n",
    "downloadedDir = rootDir_local + '02_downloaded/'\n",
    "processingDir = rootDir_local + '03_processing/'\n",
    "result_localDir = rootDir_local + '05a_result_local/'\n",
    "if process_on_VDI:\n",
    "    processedDir = rootDir_L + '04_processed/' \n",
    "    unprocessedDir = rootDir_L + '04a_unprocessed/'\n",
    "    resultDir = rootDir_L + '05_result/' \n",
    "    logDir = rootDir_L + '06_log/'\n",
    "    move_to_L = True\n",
    "else:\n",
    "    processedDir = rootDir_local + '04_processed/' \n",
    "    unprocessedDir = rootDir_local + '04a_unprocessed/' \n",
    "    resultDir = rootDir_local + '05_result/' \n",
    "    logDir = rootDir_local + '06_log/'\n",
    "    move_to_L = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8b145",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86ad74",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a0ef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(old_dir, new_dir, directory, subdir, copy_to_other_drive=False, delete_old_dir=False):\n",
    "    oldDir = old_dir + directory + '/' + subdir + '/'\n",
    "    newDir = new_dir + directory + '/' + subdir + '/'\n",
    "    os.makedirs(newDir, exist_ok=True)\n",
    "    \n",
    "    if copy_to_other_drive:\n",
    "        if os.path.exists(oldDir):\n",
    "            for file in os.listdir(oldDir):\n",
    "                shutil.copyfile(oldDir+file, newDir+file)\n",
    "    else:\n",
    "        if os.path.exists(oldDir):\n",
    "            for file in os.listdir(oldDir):\n",
    "                os.rename(oldDir+file, newDir+file)\n",
    "    \n",
    "    if delete_old_dir:\n",
    "        if os.path.exists(oldDir):\n",
    "            shutil.rmtree(old_dir + directory + '/' + subdir + '/')\n",
    "            if len(os.listdir(old_dir + directory + '/')) == 0:\n",
    "                shutil.rmtree(old_dir + directory + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdd51f",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4d331",
   "metadata": {},
   "source": [
    "#### Check if any subdirectories are waiting to be processed, then process them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3e898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stop_condition = False\n",
    "stop_condition_counter = 0\n",
    "\n",
    "while stop_condition == False:\n",
    "    if len(os.listdir(downloadedDir)) > 0:\n",
    "        for directory in os.listdir(downloadedDir):\n",
    "            if 'R' in directory:\n",
    "                for subdirectory in os.listdir(downloadedDir + directory):\n",
    "                    start = time.time()\n",
    "                    subdir_path_end = directory + '/' + subdirectory + '/'\n",
    "\n",
    "                    #Move to '03_processing'\n",
    "                    move_images(old_dir=downloadedDir, new_dir=processingDir, directory=directory, subdir=subdirectory)\n",
    "                    \n",
    "                    #Clear intermediate results in result_localDir\n",
    "                    for file in os.listdir(result_localDir):\n",
    "                        if 'df' in file:\n",
    "                            os.remove(result_localDir + file)\n",
    "                        else:\n",
    "                            shutil.rmtree(result_localDir + file)\n",
    "\n",
    "                    #Process\n",
    "                    print('')\n",
    "                    print('Processing ' + subdir_path_end + ' subdirectory...')\n",
    "                    !python scan2data/user_input.py $processingDir $result_localDir\n",
    "\n",
    "                    #Consolidate results\n",
    "                    if os.path.exists(result_localDir + 'df_dot.csv'):\n",
    "                        df_dot = pd.read_csv(result_localDir + 'df_dot.csv')\n",
    "                        n_dot = len(df_dot)\n",
    "                        df_dot['processed_image_class'] = 'dot'\n",
    "                        os.remove(result_localDir + 'df_dot.csv')\n",
    "                    else:\n",
    "                        df_dot = pd.DataFrame()\n",
    "                        n_dot = 0\n",
    "\n",
    "                    if os.path.exists(result_localDir + 'df_num.csv'):\n",
    "                        df_num = pd.read_csv(result_localDir + 'df_num.csv')\n",
    "                        n_num = len(df_num)\n",
    "                        df_num['processed_image_class'] = 'num'\n",
    "                        os.remove(result_localDir + 'df_num.csv')\n",
    "                    else:\n",
    "                        df_num = pd.DataFrame()\n",
    "                        n_num = 0\n",
    "\n",
    "                    if os.path.exists(result_localDir + 'df_loss.csv'):\n",
    "                        df_loss = pd.read_csv(result_localDir + 'df_loss.csv')\n",
    "                        n_loss = len(df_loss)\n",
    "                        df_loss['processed_image_class'] = 'loss'\n",
    "                        os.remove(result_localDir + 'df_loss.csv')\n",
    "                    else:\n",
    "                        df_loss = pd.DataFrame()\n",
    "                        n_loss = 0\n",
    "\n",
    "                    if os.path.exists(result_localDir + 'df_outlier.csv'):\n",
    "                        df_outlier = pd.read_csv(result_localDir + 'df_outlier.csv')\n",
    "                        n_outlier = len(df_outlier)\n",
    "                        df_outlier['processed_image_class'] = 'outlier'\n",
    "                        os.remove(result_localDir + 'df_outlier.csv')\n",
    "                    else:\n",
    "                        df_outlier = pd.DataFrame()\n",
    "                        n_outlier = 0\n",
    "\n",
    "                    df_tot = pd.concat([df_dot, df_num, df_loss, df_outlier])\n",
    "                    if len(df_tot) > 0:\n",
    "                        df_tot['Directory'] = directory\n",
    "                        df_tot['Subdirectory'] = subdirectory\n",
    "                        if 'file_name' in df_tot.columns:\n",
    "                            df_tot['filename'] = df_tot['file_name'].str.replace(processingDir + directory + '/' + subdirectory, '')\n",
    "                            df_tot['filename'] = df_tot['filename'].str.replace('\\\\', '')\n",
    "                            df_tot['filename'] = df_tot['filename'].str.replace('/', '')\n",
    "                        else:\n",
    "                            df_tot['filename'] = 'unknown'\n",
    "                        df_tot = df_tot.drop(columns=['file_name', 'mapped_coord', 'subdir_name', 'raw', 'ionogram', 'raw_metadata', \n",
    "                                                      'trimmed_metadata', 'padded', 'dilated_metadata'], errors='ignore')\n",
    "                    os.makedirs(resultDir + directory + '/', exist_ok=True)\n",
    "                    df_tot.to_csv(resultDir + directory + '/' + 'result-' + directory + '_' + subdirectory + '.csv', index=False)\n",
    "                    \n",
    "                    #move mapped_coords to '05_result'\n",
    "                    mapped_coords_localDir = result_localDir + 'mapped_coords/'\n",
    "                    mapped_coordsDir = resultDir + 'mapped_coords/'\n",
    "                    move_images(old_dir=mapped_coords_localDir, new_dir=mapped_coordsDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    t = end - start\n",
    "                    print('Processing time for subdirectory: ' + str(round(t/60, 1)) + ' min')\n",
    "                    print('')\n",
    "                    \n",
    "                    #Record performance\n",
    "                    n_processed = n_dot + n_num + n_loss + n_outlier\n",
    "                    df_result_ = pd.DataFrame({\n",
    "                        'Directory': directory,\n",
    "                        'Subdirectory': subdirectory,\n",
    "                        'Images_processed': n_processed,\n",
    "                        'Images_dot': n_dot,\n",
    "                        'Images_num': n_num,\n",
    "                        'Images_loss': n_loss,\n",
    "                        'Images_outlier': n_outlier,\n",
    "                        'Process_time': t,\n",
    "                        'Process_timestamp': datetime.fromtimestamp(end),\n",
    "                        'User': user,\n",
    "                        'subdir_id': directory + '_' + subdirectory\n",
    "                    }, index=[0])\n",
    "                    if os.path.exists(logDir + 'process_log.csv'):\n",
    "                        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "                        df_update = pd.concat([df_log, df_result_], axis=0, ignore_index=True)\n",
    "                        df_update.to_csv(logDir + 'process_log.csv', index=False)\n",
    "                    else:\n",
    "                        if len(df_result_) > 0:\n",
    "                            df_result_.to_csv(logDir + 'process_log.csv', index=False)\n",
    "                    \n",
    "                    #Backup 'process_log' (10% of the time)\n",
    "                    if randrange(10) == 7:\n",
    "                        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "                        datetime_str = datetime.now().strftime(\"%Y%m%d_%Hh%M\")\n",
    "                        os.makedirs(logDir + 'backups/', exist_ok=True)\n",
    "                        df_log.to_csv(logDir + 'backups/' + 'process_log-' + datetime_str + '.csv', index=False)\n",
    "                    \n",
    "                    #Move to '04_processed' or '04a_unprocessed'\n",
    "                    if n_processed > 0:\n",
    "                        move_images(old_dir=processingDir, new_dir=processedDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L, delete_old_dir=True)\n",
    "                    else:\n",
    "                        move_images(old_dir=processingDir, new_dir=unprocessedDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L, delete_old_dir=True)\n",
    "                    \n",
    "                    stop_condition_counter += 1\n",
    "    \n",
    "    else:\n",
    "        #Wait\n",
    "        print('Wait ' + str(wait) + ' min')\n",
    "        time.sleep(wait*60)\n",
    "\n",
    "        \n",
    "    #Check stop conditions\n",
    "    if stop_condition_counter == stop_loop_threshold:\n",
    "        print('Stop!')\n",
    "        stop_condition = True\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d51e7e",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ce545",
   "metadata": {},
   "source": [
    "#### Re-process list of subdirectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d92172",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2638\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roll</th>\n",
       "      <th>Subdirectory</th>\n",
       "      <th>images</th>\n",
       "      <th>subdir_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>R014207832</td>\n",
       "      <td>3627-19A</td>\n",
       "      <td>306</td>\n",
       "      <td>R014207832_3627-19A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>R014207979F</td>\n",
       "      <td>284</td>\n",
       "      <td>437</td>\n",
       "      <td>R014207979F_284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>R014207930F</td>\n",
       "      <td>615</td>\n",
       "      <td>74</td>\n",
       "      <td>R014207930F_615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>R014207909F</td>\n",
       "      <td>707</td>\n",
       "      <td>370</td>\n",
       "      <td>R014207909F_707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>R014207816</td>\n",
       "      <td>3396-A13</td>\n",
       "      <td>303</td>\n",
       "      <td>R014207816_3396-A13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Roll Subdirectory  images            subdir_id\n",
       "319    R014207832     3627-19A     306  R014207832_3627-19A\n",
       "2561  R014207979F          284     437      R014207979F_284\n",
       "840   R014207930F          615      74      R014207930F_615\n",
       "741   R014207909F          707     370      R014207909F_707\n",
       "88     R014207816     3396-A13     303  R014207816_3396-A13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reprocess = pd.read_csv(logDir + 'image_inventory.csv') #reprocess_list.csv\n",
    "df_reprocess = df_reprocess.sample(frac=1)\n",
    "print(len(df_reprocess))\n",
    "df_reprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1717845",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprocess_list = ['R014207838_4559-50'] #df_reprocess['subdir_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2889339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing R014207838/4559-50/ subdirectory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"scan2data/user_input.py\", line 35, in <module>\n",
      "    main()\n",
      "  File \"scan2data/user_input.py\", line 25, in main\n",
      "    process_directory.process_extract_management(dir_csv_output, master_dir, regex_raw, sample_subdir)\n",
      "  File \"C:\\Users\\rnaidoo\\Documents\\Projects\\SuperVDI1\\Alouette_extract\\scan2data\\process_directory.py\", line 134, in process_extract_management\n",
      "    df_processed, df_loss, df_outlier = process_subdirectory(sample_subdir, regex_raw)\n",
      "  File \"C:\\Users\\rnaidoo\\Documents\\Projects\\SuperVDI1\\Alouette_extract\\scan2data\\process_directory.py\", line 66, in process_subdirectory\n",
      "    df_img_bottom, df_loss_meta_bottom, dict_mapping_bottom, dict_hist_bottom = get_bottomside_metadata(df_img_bottom, subdir_path) #from metadata_translation.translate_bottomside_metadata\n",
      "  File \"C:\\Users\\rnaidoo\\Documents\\Projects\\SuperVDI1\\Alouette_extract\\scan2data\\metadata_translation\\translate_leftside_metadata.py\", line 158, in get_bottomside_metadata\n",
      "    df_num_subset = df_img[np.invert(np.array(df_img['is_dot']))]\n",
      "  File \"U:\\temp\\rnaidoo\\Python\\envs\\Alouette_on_RavSuperVDI1\\lib\\site-packages\\pandas\\core\\frame.py\", line 3813, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "  File \"U:\\temp\\rnaidoo\\Python\\envs\\Alouette_on_RavSuperVDI1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6070, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"U:\\temp\\rnaidoo\\Python\\envs\\Alouette_on_RavSuperVDI1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6130, in _raise_if_missing\n",
      "    raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n",
      "KeyError: \"None of [Int64Index([-1, -1, -1, -1, -1, -1, -1, -2, -1, -1,\\n            ...\\n            -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\\n           dtype='int64', length=228)] are in the [columns]\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time for subdirectory: 1.4 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subdir in reprocess_list:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    subdir_id_parts = subdir.split('_')\n",
    "    directory = subdir_id_parts[0]\n",
    "    subdirectory = subdir_id_parts[1]\n",
    "    subdir_path_end = directory + '/' + subdirectory + '/'\n",
    "    \n",
    "    #Clear any old subdirectories in processingDir\n",
    "    for file in os.listdir(processingDir):\n",
    "        if 'R' in file:\n",
    "            shutil.rmtree(processingDir + file)\n",
    "    \n",
    "    #Clear intermediate results in result_localDir\n",
    "    for file in os.listdir(result_localDir):\n",
    "        if 'df' in file:\n",
    "            os.remove(result_localDir + file)\n",
    "        else:\n",
    "            shutil.rmtree(result_localDir + file)\n",
    "    \n",
    "    #Retrieve subdirectory\n",
    "    if os.path.exists(processedDir + subdir_path_end):\n",
    "        move_images(old_dir=processedDir, new_dir=processingDir, directory=directory, subdir=subdirectory, copy_to_other_drive=True)\n",
    "    elif os.path.exists(unprocessedDir + subdir_path_end):\n",
    "        move_images(old_dir=unprocessedDir, new_dir=processingDir, directory=directory, subdir=subdirectory, copy_to_other_drive=True)\n",
    "    else:\n",
    "        print('Cannot find subdirectory ' + subdir + '!')\n",
    "        continue\n",
    "    \n",
    "    #Process\n",
    "    print('')\n",
    "    print('Processing ' + subdir_path_end + ' subdirectory...')\n",
    "    !python scan2data/user_input.py $processingDir $result_localDir\n",
    "\n",
    "    #Consolidate results\n",
    "    if os.path.exists(result_localDir + 'df_dot.csv'):\n",
    "        df_dot = pd.read_csv(result_localDir + 'df_dot.csv')\n",
    "        n_dot = len(df_dot)\n",
    "        df_dot['processed_image_class'] = 'dot'\n",
    "        os.remove(result_localDir + 'df_dot.csv')\n",
    "    else:\n",
    "        df_dot = pd.DataFrame()\n",
    "        n_dot = 0\n",
    "\n",
    "    if os.path.exists(result_localDir + 'df_num.csv'):\n",
    "        df_num = pd.read_csv(result_localDir + 'df_num.csv')\n",
    "        n_num = len(df_num)\n",
    "        df_num['processed_image_class'] = 'num'\n",
    "        os.remove(result_localDir + 'df_num.csv')\n",
    "    else:\n",
    "        df_num = pd.DataFrame()\n",
    "        n_num = 0\n",
    "\n",
    "    if os.path.exists(result_localDir + 'df_loss.csv'):\n",
    "        df_loss = pd.read_csv(result_localDir + 'df_loss.csv')\n",
    "        n_loss = len(df_loss)\n",
    "        df_loss['processed_image_class'] = 'loss'\n",
    "        os.remove(result_localDir + 'df_loss.csv')\n",
    "    else:\n",
    "        df_loss = pd.DataFrame()\n",
    "        n_loss = 0\n",
    "\n",
    "    if os.path.exists(result_localDir + 'df_outlier.csv'):\n",
    "        df_outlier = pd.read_csv(result_localDir + 'df_outlier.csv')\n",
    "        n_outlier = len(df_outlier)\n",
    "        df_outlier['processed_image_class'] = 'outlier'\n",
    "        os.remove(result_localDir + 'df_outlier.csv')\n",
    "    else:\n",
    "        df_outlier = pd.DataFrame()\n",
    "        n_outlier = 0\n",
    "\n",
    "    df_tot = pd.concat([df_dot, df_num, df_loss, df_outlier])\n",
    "    if len(df_tot) > 0:\n",
    "        df_tot['Directory'] = directory\n",
    "        df_tot['Subdirectory'] = subdirectory\n",
    "        if 'file_name' in df_tot.columns:\n",
    "            df_tot['filename'] = df_tot['file_name'].str.replace(processingDir + directory + '/' + subdirectory, '')\n",
    "            df_tot['filename'] = df_tot['filename'].str.replace('\\\\', '')\n",
    "            df_tot['filename'] = df_tot['filename'].str.replace('/', '')\n",
    "        else:\n",
    "            df_tot['filename'] = 'unknown'\n",
    "        df_tot = df_tot.drop(columns=['file_name', 'mapped_coord', 'subdir_name', 'raw', 'ionogram', 'raw_metadata', \n",
    "                                      'trimmed_metadata', 'padded', 'dilated_metadata'], errors='ignore')\n",
    "    os.makedirs(resultDir + directory + '/', exist_ok=True)\n",
    "    df_tot.to_csv(resultDir + directory + '/' + 'result-' + directory + '_' + subdirectory + '.csv', index=False)\n",
    "\n",
    "    #move mapped_coords to '05_result'\n",
    "    mapped_coords_localDir = result_localDir + 'mapped_coords/'\n",
    "    mapped_coordsDir = resultDir + 'mapped_coords/'\n",
    "    move_images(old_dir=mapped_coords_localDir, new_dir=mapped_coordsDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L)\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print('Processing time for subdirectory: ' + str(round(t/60, 1)) + ' min')\n",
    "    print('')\n",
    "\n",
    "    #Record performance\n",
    "    n_processed = n_dot + n_num + n_loss + n_outlier\n",
    "    df_result_ = pd.DataFrame({\n",
    "        'Directory': directory,\n",
    "        'Subdirectory': subdirectory,\n",
    "        'Images_processed': n_processed,\n",
    "        'Images_dot': n_dot,\n",
    "        'Images_num': n_num,\n",
    "        'Images_loss': n_loss,\n",
    "        'Images_outlier': n_outlier,\n",
    "        'Process_time': t,\n",
    "        'Process_timestamp': datetime.fromtimestamp(end),\n",
    "        'User': user,\n",
    "        'subdir_id': directory + '_' + subdirectory\n",
    "    }, index=[0])\n",
    "    if os.path.exists(logDir + 'process_log.csv'):\n",
    "        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "        df_update = pd.concat([df_log, df_result_], axis=0, ignore_index=True)\n",
    "        df_update.to_csv(logDir + 'process_log.csv', index=False)\n",
    "    else:\n",
    "        if len(df_result_) > 0:\n",
    "            df_result_.to_csv(logDir + 'process_log.csv', index=False)\n",
    "\n",
    "    #Backup 'process_log' (10% of the time)\n",
    "    if randrange(10) == 7:\n",
    "        df_log = pd.read_csv(logDir + 'process_log.csv')\n",
    "        datetime_str = datetime.now().strftime(\"%Y%m%d_%Hh%M\")\n",
    "        os.makedirs(logDir + 'backups/', exist_ok=True)\n",
    "        df_log.to_csv(logDir + 'backups/' + 'process_log-' + datetime_str + '.csv', index=False)\n",
    "\n",
    "    #Move to '04_processed' or '04a_unprocessed'\n",
    "    if n_processed > 0:\n",
    "        move_images(old_dir=processingDir, new_dir=processedDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L, delete_old_dir=True)\n",
    "    else:\n",
    "        move_images(old_dir=processingDir, new_dir=unprocessedDir, directory=directory, subdir=subdirectory, copy_to_other_drive=move_to_L, delete_old_dir=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0b158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
