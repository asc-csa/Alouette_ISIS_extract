{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f541a6",
   "metadata": {},
   "source": [
    "# Alouette Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a266a9",
   "metadata": {},
   "source": [
    "The Data Dictionary of Alouette was prepared based on the PDS4 Data Dictionary Standards with slight modifications. For more information on PDS4 please consult the following link: https://pds.nasa.gov/datastandards/documents/dd/all/current/\n",
    "\n",
    "The code below starts with initializing the helper function, from there it will specify the desired files to be analyzed. The user will be able to follow the promps in console to fill the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f69d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e5613",
   "metadata": {},
   "source": [
    "### Function Initialization Section\n",
    "\n",
    "Please run the cells below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98daf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading in CSV and Excel documents. Other data types to be supported in the future\n",
    "def read_file(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        data = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        data = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please upload a CSV or XLSX file.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if column has a header and uses as name, otherwise is Unamed, could be updated to have user define name if no name\n",
    "def get_column_name(column):\n",
    "    if column.name is not None:\n",
    "        return column.name\n",
    "    else:\n",
    "        return \"Unnamed_Column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee979518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts user for a description\n",
    "def get_user_description(column_name):\n",
    "    print(f\"Please provide a description for the column '{column_name}': \")\n",
    "    description = input() \n",
    "    return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the user select a unit from the list of available. This list can be adjusted to simplfy\n",
    "def get_unit_selection(column_name):\n",
    "    units_list = [\"Unit_Of_Measure\",\n",
    "    \"Units_of_Acceleration\",\n",
    "    \"Units_of_Amount_Of_Substance\",\n",
    "    \"Units_of_Angle\",\n",
    "    \"Units_of_Angular_Velocity\",\n",
    "    \"Units_of_Area\",\n",
    "    \"Units_of_Current\",\n",
    "    \"Units_of_Energy\",\n",
    "    \"Units_of_Force\",\n",
    "    \"Units_of_Frame_Rate\",\n",
    "    \"Units_of_Frequency\",\n",
    "    \"Units_of_Gmass\",\n",
    "    \"Units_of_Length\",\n",
    "    \"Units_of_Map_Scale\",\n",
    "    \"Units_of_Mass\",\n",
    "    \"Units_of_Mass_Density\",\n",
    "    \"Units_of_Misc\",\n",
    "    \"Units_of_None\",\n",
    "    \"Units_of_Optical_Path_Length\",\n",
    "    \"Units_of_Pixel_Resolution_Angular\",\n",
    "    \"Units_of_Pixel_Resolution_Linear\",\n",
    "    \"Units_of_Pixel_Resolution_Map\",\n",
    "    \"Units_of_Pixel_Scale_Angular\",\n",
    "    \"Units_of_Pixel_Scale_Linear\",\n",
    "    \"Units_of_Pixel_Scale_Map\",\n",
    "    \"Units_of_Power\",\n",
    "    \"Units_of_Pressure\",\n",
    "    \"Units_of_Radiance\",\n",
    "    \"Units_of_Rates\",\n",
    "    \"Units_of_Solid_Angle\",\n",
    "    \"Units_of_Spectral_Irradiance\",\n",
    "    \"Units_of_Spectral_Radiance\",\n",
    "    \"Units_of_Storage\",\n",
    "    \"Units_of_Temperature\",\n",
    "    \"Units_of_Time\",\n",
    "    \"Units_of_Velocity\",\n",
    "    \"Units_of_Voltage\",\n",
    "    \"Units_of_Volume\",\n",
    "    \"Units_of_Wavenumber\"]\n",
    "                  \n",
    "    print(f\"Please select a unit for the column '{column_name}' from the following list:\")\n",
    "    print(*units_list, sep = '\\n')\n",
    "    unit = input() \n",
    "    if unit not in units_list:\n",
    "        print(\"Invalid unit selected. Defaulting to 'Unit_of_None'.\")\n",
    "        unit = \"Unit_of_None\"\n",
    "    return unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the user define a broad category with the user defining a specific type (or defaulting if user is not sure)\n",
    "def get_data_type(column_name):\n",
    "    \n",
    "    type_list = [\"Date_Time\",\n",
    "    \"File_Name\",\n",
    "    \"Numeric\",\n",
    "    \"Identifier\",\n",
    "    \"String\",\n",
    "    \"Misc\"]\n",
    "    \n",
    "    date_list = ['ASCII_DOI', 'ASCII_Date', 'ASCII_Time', 'ASCII_Time_GPS', 'ASCII_Date_DOY', 'ASCII_Date_Time', 'ASCII_Date_Time_UTC', 'ASCII_Date_Time_YMD', 'ASCII_Date_Time_DMY', 'ASCII_Date_Time_MDY']\n",
    "    \n",
    "    file_list = ['ASCII_Directory_Path_Name', 'ASCII_File_Name', 'ASCII_File_Specfication_Name']\n",
    "    \n",
    "    numeric_list = ['ASCII_Integer', 'ASCII_NonNegative_Integer', 'ASCII_Real', 'ASCII_Complex', 'ASCII_Checksum', 'ASCII_Numeric', 'ASCII_Float', 'ASCII_Double']\n",
    "    \n",
    "    iden_list = ['ASCII_Boolean', 'ASCII_Reference', 'ASCII_Local_Identifier', 'ASCII_Local_Identifier_Reference', 'ASCII_Identifier']\n",
    "    \n",
    "    string_list = ['ASCII_String', 'ASCII_Char', 'ASCII_Text']\n",
    "                  \n",
    "    print(f\"Please select an overall data type for the column '{column_name}' from the following list:\")\n",
    "    print(*type_list, sep = '\\n')\n",
    "    data_type = input() \n",
    "    \n",
    "    if data_type not in type_list:\n",
    "        print(\"Invalid type selected. Defaulting to 'ASCII_Misc'.\")\n",
    "        data_type = \"ASCII_Misc\"\n",
    "        \n",
    "    elif data_type == \"Date_Time\":\n",
    "        clear_output()\n",
    "        print(f\"Please select a Date Time type for '{column_name}' from the following list:\")\n",
    "        print(*date_list, sep = '\\n')\n",
    "        data_type = input() \n",
    "        if data_type not in date_list:\n",
    "            print(\"Invalid type selected. Defaulting to 'ASCII_Date_Time'.\")\n",
    "            data_type = \"ASCII_Date_Time\"\n",
    "            \n",
    "    elif data_type == \"File_Name\":\n",
    "        clear_output()\n",
    "        print(f\"Please select a Date Time type for '{column_name}' from the following list:\")\n",
    "        print(*file_list, sep = '\\n')\n",
    "        data_type = input() \n",
    "        if data_type not in file_list:\n",
    "            print(\"Invalid type selected. Defaulting to 'ASCII_File_Name'.\")\n",
    "            data_type = \"ASCII_File_Name\"\n",
    "            \n",
    "    elif data_type == \"Numeric\":\n",
    "        clear_output()\n",
    "        print(f\"Please select a Date Time type for '{column_name}' from the following list:\")\n",
    "        print(*numeric_list, sep = '\\n')\n",
    "        data_type = input() \n",
    "        if data_type not in numeric_list:\n",
    "            print(\"Invalid type selected. Defaulting to 'ASCII_Numeric'.\")\n",
    "            data_type = \"ASCII_Numeric\"\n",
    "            \n",
    "    elif data_type == \"Identifier\":\n",
    "        clear_output()\n",
    "        print(f\"Please select a Date Time type for '{column_name}' from the following list:\")\n",
    "        print(*iden_list, sep = '\\n')\n",
    "        data_type = input() \n",
    "        if data_type not in iden_list:\n",
    "            print(\"Invalid type selected. Defaulting to 'ASCII_Identifier'.\")\n",
    "            data_type = \"ASCII_Identifier\"\n",
    "\n",
    "    elif data_type == \"String\":\n",
    "        clear_output()\n",
    "        print(f\"Please select a Date Time type for '{column_name}' from the following list:\")\n",
    "        print(*string_list, sep = '\\n')\n",
    "        data_type = input() \n",
    "        if data_type not in string_list:\n",
    "            print(\"Invalid type selected. Defaulting to 'ASCII_String'.\")\n",
    "            data_type = \"ASCII_String\"\n",
    "            \n",
    "    elif data_type == \"Misc\":\n",
    "        clear_output()\n",
    "        data_type = \"ASCII_Misc\"\n",
    "\n",
    "\n",
    "    return data_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the data type specfied by the user, statistics of the data is derived \n",
    "def get_data_stats(data_type, column):\n",
    "        \n",
    "    date_list = ['ASCII_DOI', 'ASCII_Date', 'ASCII_Time', 'ASCII_Time_GPS', 'ASCII_Date_DOY', 'ASCII_Date_Time', 'ASCII_Date_Time_UTC', 'ASCII_Date_Time_YMD', 'ASCII_Date_Time_DMY', 'ASCII_Date_Time_MDY']\n",
    "    \n",
    "    file_list = ['ASCII_Directory_Path_Name', 'ASCII_File_Name', 'ASCII_File_Specfication_Name']\n",
    "    \n",
    "    numeric_list = ['ASCII_Integer', 'ASCII_NonNegative_Integer', 'ASCII_Real', 'ASCII_Complex', 'ASCII_Checksum', 'ASCII_Numeric', 'ASCII_Float', 'ASCII_Double']\n",
    "    \n",
    "    iden_list = ['ASCII_Boolean', 'ASCII_Reference', 'ASCII_Local_Identifier', 'ASCII_Local_Identifier_Reference', 'ASCII_Identifier']\n",
    "    \n",
    "    string_list = ['ASCII_String', 'ASCII_Char', 'ASCII_Text']\n",
    "    \n",
    "    if data_type in date_list:\n",
    "        return [float('NaN')]\n",
    "    \n",
    "    elif data_type in file_list:\n",
    "        try:\n",
    "            vals = [column.map(len).min(), column.map(len).max(), column.size]\n",
    "        except:\n",
    "            vals = [float('NaN')]\n",
    "        return vals\n",
    "    \n",
    "    elif data_type in numeric_list:\n",
    "        try:\n",
    "            vals = [column.min(), column.max(), column.size]\n",
    "        except: \n",
    "            vals = [float('NaN')]\n",
    "        return vals\n",
    "    \n",
    "    elif data_type in iden_list:\n",
    "        try: \n",
    "            vals = [column.map(len).min(), column.map(len).max(), column.size]\n",
    "        except:\n",
    "            vals = [column.min(), column.max(), column.size]\n",
    "        return vals\n",
    "    \n",
    "    elif data_type in string_list:\n",
    "        try: \n",
    "            vals = [column.map(len).min(), column.map(len).max(), column.size]\n",
    "        except:\n",
    "            vals = [float('NaN')]\n",
    "        return vals\n",
    "    \n",
    "    else:\n",
    "        return [float('NaN')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_path):\n",
    "    # Read the file into a DataFrame\n",
    "    data = read_file(file_path)\n",
    "    \n",
    "    # Create an empty DataFrame to store the analysis results\n",
    "    analysis_df = pd.DataFrame(columns=['Column_Name', 'Description', 'Data_Type', 'Stats', 'Units'])\n",
    "    \n",
    "    # Iterate over columns to perform analysis and populate the analysis DataFrame\n",
    "    for column in data.columns:\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        column_name = get_column_name(data[column])\n",
    "        \n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        description = get_user_description(column)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        data_type = get_data_type(column)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        stats = get_data_stats(data_type, data[column])\n",
    "        \n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)\n",
    "        units = get_unit_selection(column)\n",
    "        \n",
    "        new_row = {'Column_Name': column_name, 'Description': description, 'Data_Type': data_type, 'Stats': stats, 'Units': units}\n",
    "        \n",
    "        analysis_df.loc[len(analysis_df)] = new_row\n",
    "        \n",
    "    \n",
    "    return analysis_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833b26c",
   "metadata": {},
   "source": [
    "### Analysis Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1adc8ab",
   "metadata": {},
   "source": [
    "To replicate our work you can access the .csv files through the following two options\n",
    "\n",
    "1) Downloading from Open data portal of Canadian Spaace Agency: https://donnees-data.asc-csa.gc.ca/en/dataset/221c1c75-4c42-4286-a4ce-ca6c3027b7fe\n",
    "2) Generatig the .csv files by running  \"Alouette_processor\", \"Alouette_processor2, \"E-Satellite tracking processing\" and \"F_Prepare result_master for Alouette Microapplication\" scripts on GitHub via the following link: https://github.com/asc-csa/Alouette_extract/tree/master/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919282a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run to check for name of the file.\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4860d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run to perform actual analysis\n",
    "analyzed_results = analyze_file('result_microapp.csv')\n",
    "\n",
    "# saves results to a csv\n",
    "analyzed_results.to_csv('dd_result_microapp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecbae02",
   "metadata": {},
   "source": [
    "### Final Processing\n",
    "\n",
    "Following the creation of data dictionaries associated with a given set of processed data, it is helpful to combine the results into a single bundle. \n",
    "\n",
    "1) Select and copy the paths of the processed data dictionaries. \n",
    "2) Run the cell below to combine into a single structured workbook (Excel) \n",
    "3) Add an additional sheet in the combined_data_dictionary manually to serve as an overview page.\n",
    "\n",
    "You can find the final data dictionary for Alouette-1 here: https://github.com/asc-csa/Alouette_extract/tree/master/documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a358bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of sub-data dictionaries to be combined\n",
    "csv_files = ['dd_result_master.csv', 'dd_result_master_orbit.csv', 'dd_result_microapp.csv']  \n",
    "\n",
    "# Create a Pandas Excel writer using openpyxl to write to Excel workbook \n",
    "with pd.ExcelWriter('combined_data_dictionary.xlsx', engine='openpyxl') as writer:\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Extract filename without extension for sheet name\n",
    "        sheet_name = file.split('/')[-1].split('.')[0]\n",
    "\n",
    "        # Write DataFrame to an Excel sheet\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20be6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
